02-18-2019 11:44:09 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53275/api/v1/applications/application_1
02-18-2019 11:44:10 INFO  [ForkJoinPool-1-worker-13] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53275/api/v1/applications/application_1
02-18-2019 11:44:10 INFO  [ForkJoinPool-1-worker-1] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53275/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 11:44:10 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53282/api/v1/applications/application_1
02-18-2019 11:44:10 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : creating SparkApplication by calling REST API at http://localhost:53282/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 11:44:10 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53284/api/v1/applications/application_1
02-18-2019 11:44:10 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : creating SparkApplication by calling REST API at http://localhost:53284/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 11:44:10 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53286/api/v1/applications/application_1
02-18-2019 11:44:10 INFO  [ForkJoinPool-1-worker-1] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53286/api/v1/applications/application_1
02-18-2019 11:44:10 INFO  [ForkJoinPool-1-worker-11] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53286/api/v1/applications/application_1/logs to get eventlogs
02-18-2019 11:44:10 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53292/api/v1/applications/application_1
02-18-2019 11:44:11 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53297/api/v1/applications?status=completed&minEndDate=2019-02-18T06%3A10%3A51.087GMT&maxEndDate=2019-02-18T06%3A16%3A11.087GMT
02-18-2019 11:44:11 WARN  [pool-1-thread-1-ScalaTest-running-SparkMetricsAggregatorTest] com.linkedin.drelephant.spark.SparkMetricsAggregator : applicationDurationMillis is negative. Skipping Metrics Aggregation:-8000000
02-18-2019 11:44:11 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 50.0 MB
02-18-2019 11:44:11 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 11:44:11 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 11:44:11 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 11:44:11 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 11:44:11 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 11:44:11 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 11:44:11 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 11:44:11 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : Replaying Spark logs for application: application_1 withlogPath: webhdfs://nn1.grid.example.com:50070/logs/spark/application_1_1.snappy with codec:Some(org.apache.spark.io.SnappyCompressionCodec@15b9c8a2)
02-18-2019 11:44:11 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : Replay completed for application: application_1
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Succeeded fetching data for application_1
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 11:44:12 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 11:44:12 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Succeeded fetching data for application_1
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 11:44:12 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:44:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 200.0 MB
02-18-2019 11:44:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 11:44:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:44:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:44:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFetcher : appId needs sampling.
02-18-2019 11:44:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:44:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 11:44:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:44:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:44:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:44:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: GMT
02-18-2019 11:44:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:44:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Found job config in intermediate dir: test/resources/history/done_intermediate/user/job_1526555215992_0004_conf.xml
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Found history file in intermediate dir: test/resources/history/done_intermediate/user/job_1526555215992_0004-1526567229183-user-QuasiMonteCarlo-1526567243482-1-1-SUCCEEDED-default-1526567234171.jhist
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: GMT
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:44:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@5cd67789 fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@2e9f645 fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 11:44:15 INFO  [Thread-34] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Starting Auto Tuning thread
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 11:44:15 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : No login user. Creating login user
02-18-2019 11:44:15 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Logging with null and null
02-18-2019 11:44:15 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Logged in with user pkumar2 (auth:SIMPLE)
02-18-2019 11:44:15 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Login is not keytab based
02-18-2019 11:44:15 INFO  [Thread-34] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager HBT
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager OBT
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Azkaban Job Status Manager
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager HBT
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerHBT
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT PSO
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoPSO
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT IPSO
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoIPSO
02-18-2019 11:44:15 INFO  [Thread-34] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT MR
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT Spark
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO MR
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO Spark
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO MR
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO Spark
02-18-2019 11:44:15 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 11:44:15 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 11:44:15 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 11:44:15 ERROR [Thread-34] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 11:44:15 ERROR [Thread-34] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 11:44:15 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 0
02-18-2019 11:44:15 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Baseline Done 
02-18-2019 11:44:15 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 11:44:15 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 11:44:15 INFO  [Thread-35] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 11:44:15 INFO  [Thread-35] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Baseline Done 
02-18-2019 11:44:15 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 11:44:15 INFO  [Thread-36] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 11:44:15 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 11:44:15 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 11:44:15 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 0
02-18-2019 11:44:15 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Baseline Done
02-18-2019 11:44:15 INFO  [Thread-36] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false AzkabanJobStatusManager
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 0
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 0
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fitness Computed
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerHBT
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoPSO
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Executing Fitness Manager
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Fitness Computed
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoPSO
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoIPSO
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Executing Fitness Manager
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Fitness Computed
02-18-2019 11:44:15 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoIPSO
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : No auto-tuning enabled jobs found
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : No auto-tuning enabled jobs found
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:15 ERROR [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Error in auto tuner thread 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at com.linkedin.drelephant.tuning.AutoTuningFlow.executeFlow(AutoTuningFlow.java:46)
	at com.linkedin.drelephant.AutoTuner.run(AutoTuner.java:58)
	at java.lang.Thread.run(Thread.java:748)
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : No auto-tuning enabled jobs found
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Param Generation Done
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : No auto-tuning enabled jobs found
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Param Generation Done
02-18-2019 11:44:15 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 1
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 0
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager HBT
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager OBT
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Azkaban Job Status Manager
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager HBT
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerHBT
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT PSO
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoPSO
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT IPSO
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoIPSO
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT MR
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT Spark
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO MR
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO Spark
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO MR
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO Spark
02-18-2019 11:44:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-51] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 11:44:15 INFO  [Thread-51] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 11:44:15 INFO  [Thread-51] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 11:44:15 ERROR [Thread-51] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT :  Execution of the base line manager is failed java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT.detectJobsForBaseLineComputation(BaselineManagerHBT.java:28)
	at com.linkedin.drelephant.tuning.AbstractBaselineManager.execute(AbstractBaselineManager.java:58)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 9 more
02-18-2019 11:44:15 INFO  [Thread-51] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 11:44:15 INFO  [Thread-51] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 11:44:15 INFO  [Thread-51] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 11:44:15 ERROR [Thread-51] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT :  Execution of the base line manager is failed java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.BaselineManagerOBT.detectJobsForBaseLineComputation(BaselineManagerOBT.java:32)
	at com.linkedin.drelephant.tuning.AbstractBaselineManager.execute(AbstractBaselineManager.java:58)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 9 more
02-18-2019 11:44:15 INFO  [Thread-51] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 11:44:15 INFO  [Thread-55] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 11:44:15 INFO  [Thread-55] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 11:44:15 INFO  [Thread-55] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 11:44:15 INFO  [Thread-56] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 11:44:15 INFO  [Thread-56] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 11:44:15 INFO  [Thread-56] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:44:15 WARN  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT.getPendingParamSets(ParameterGenerateManagerHBT.java:44)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:44:15 WARN  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT.getPendingParamSets(ParameterGenerateManagerHBT.java:44)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:15 WARN  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:15 WARN  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:15 WARN  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:15 WARN  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:44:15 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : New parameter suggestion needed for job: countByCountryFlow_countByCountry
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 1
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Getting tuning information for job: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Fetching default parameter values for job https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Fetching default parameter values for job 
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Adding JobTuningInfo {"jobType":"PIG","tuningJob":{"id":100003,"jobDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","scheduler":"azkaban","username":"pkumar2","jobName":"countByCountryFlow_countByCountry","jobDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","flowDefinition":{"id":10003,"flowDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","flowDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","createdTs":1550470456044,"updatedTs":1550470456044},"createdTs":1518405042000,"updatedTs":1518405043000},"parametersToTune":[{"id":19,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":4,"jobType":"PIG","optimizationAlgo":"HBT","optimizationAlgoVersion":4,"optimizationMetric":"RESOURCE","createdTs":1550470456000,"updatedTs":1550470456000},"defaultValue":2048.0,"minValue":1024.0,"maxValue":8192.0,"stepSize":1024.0,"createdTs":1550470456000,"updatedTs":1550470456000,"isDerived":0},{"id":20,"paramName":"mapreduce.map.java.opts","tuningAlgorithm":{"id":4,"jobType":"PIG","optimizationAlgo":"HBT","optimizationAlgoVersion":4,"optimizationMetric":"RESOURCE","createdTs":1550470456000,"updatedTs":1550470456000},"defaultValue":1536.0,"minValue":500.0,"maxValue":6144.0,"stepSize":64.0,"createdTs":1550470456000,"updatedTs":1550470456000,"isDerived":0}],"tunerState":"{}"}
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Extract Parameter Information for MR IPSO
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654676&job=overwriter-reminder2&attempt=0
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654677&job=overwriter-reminder2&attempt=0
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values Global 
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  New Suggested Parameter 19	1047.6190476190475
20	427.0

02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.OptimizationAlgoFactory : OPTIMIZATION ALGORITHM PSO_IPSO MR
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl :  IPSO Optimizer
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Extract Parameter Information for MR IPSO
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654676&job=overwriter-reminder2&attempt=0
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654677&job=overwriter-reminder2&attempt=0
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values Global 
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Optimizing Parameter Space  map
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  IPSO for map
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Optimizing Parameter Space  reduce
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  IPSO for reduce
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Constraint Violeted 
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Number of constraint(s) violated: 1
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Constraint Violeted 
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the heuristics values for last run : 
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakUnifiedMemory: 553359
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakJVMUsedMemory: 359326023
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorCore: 2
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : driverMaxPeakJVMUsedMemory: 1051344240
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedSparkDriverMemory: 2147483648
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDriverMemoryOverhead: 0
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMaxExecutors: 900
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMinExecutors: 1
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorInstances: 50
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationEnabled: true
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the suggestions for spark parameters for app id : https://hostname.com:8443/executor?execid=2136899
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorMemory 974861107
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedCore 3
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedMemoryFactor 0.05
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedDriverMemory 1948079095
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorInstances: 34
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the heuristics values for last run : 
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakUnifiedMemory: 553359
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakJVMUsedMemory: 359326023
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorCore: 1
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : driverMaxPeakJVMUsedMemory: 1051344240
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedSparkDriverMemory: 2147483648
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDriverMemoryOverhead: 0
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMaxExecutors: 30
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMinExecutors: 9
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorInstances: null
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationEnabled: true
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the suggestions for spark parameters for app id : https://hostname.com:8443/executor?execid=2136899
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorMemory 1947387940
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedCore 3
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedMemoryFactor 0.05
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedDriverMemory 1948079095
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorInstances: null
02-18-2019 11:44:16 INFO  [Thread-77] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 11:44:16 INFO  [Thread-77] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 11:44:16 INFO  [Thread-77] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 11:44:16 ERROR [Thread-77] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT :  Execution of the base line manager is failed Query threw SQLException:Column "T0.SHOW_RECOMMENDATION_COUNT" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  [42122-196] 
Bind values:[null] 
Query was:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  


javax.persistence.PersistenceException: Query threw SQLException:Column "T0.SHOW_RECOMMENDATION_COUNT" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  [42122-196] 
Bind values:[null] 
Query was:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT.detectJobsForBaseLineComputation(BaselineManagerHBT.java:28)
	at com.linkedin.drelephant.tuning.AbstractBaselineManager.execute(AbstractBaselineManager.java:58)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Column "T0.SHOW_RECOMMENDATION_COUNT" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  [42122-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.expression.ExpressionColumn.optimize(ExpressionColumn.java:147)
	at org.h2.expression.Alias.optimize(Alias.java:51)
	at org.h2.command.dml.Select.prepare(Select.java:839)
	at org.h2.command.Parser.prepareCommand(Parser.java:263)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 9 more
02-18-2019 11:44:16 INFO  [Thread-77] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 11:44:16 INFO  [Thread-77] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 11:44:16 INFO  [Thread-77] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 11:44:16 ERROR [Thread-77] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT :  Execution of the base line manager is failed Query threw SQLException:Column "T0.SHOW_RECOMMENDATION_COUNT" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  [42122-196] 
Bind values:[null] 
Query was:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  


javax.persistence.PersistenceException: Query threw SQLException:Column "T0.SHOW_RECOMMENDATION_COUNT" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  [42122-196] 
Bind values:[null] 
Query was:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.BaselineManagerOBT.detectJobsForBaseLineComputation(BaselineManagerOBT.java:32)
	at com.linkedin.drelephant.tuning.AbstractBaselineManager.execute(AbstractBaselineManager.java:58)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Column "T0.SHOW_RECOMMENDATION_COUNT" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  [42122-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.expression.ExpressionColumn.optimize(ExpressionColumn.java:147)
	at org.h2.expression.Alias.optimize(Alias.java:51)
	at org.h2.command.dml.Select.prepare(Select.java:839)
	at org.h2.command.Parser.prepareCommand(Parser.java:263)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 9 more
02-18-2019 11:44:16 INFO  [Thread-77] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 11:44:16 INFO  [Thread-78] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 11:44:16 INFO  [Thread-78] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 11:44:16 INFO  [Thread-78] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 11:44:16 INFO  [Thread-78] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 0
02-18-2019 11:44:16 INFO  [Thread-78] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Baseline Done
02-18-2019 11:44:16 INFO  [Thread-78] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false AzkabanJobStatusManager
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 0
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 0
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fitness Computed
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerHBT
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoPSO
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Executing Fitness Manager
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Fitness Computed
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoPSO
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoIPSO
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Executing Fitness Manager
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Fitness Computed
02-18-2019 11:44:16 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoIPSO
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : No auto-tuning enabled jobs found
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : No auto-tuning enabled jobs found
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : No auto-tuning enabled jobs found
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Param Generation Done
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : No auto-tuning enabled jobs found
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Param Generation Done
02-18-2019 11:44:16 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 1
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the list of executions completed since last iteration
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Checking current status of started execution: https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Initializing  AzkabanJobStatusUtil
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file SchedulerConf.xml
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: SchedulerConf.xml
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler airflow with class : com.linkedin.drelephant.schedulers.AirflowScheduler
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler azkaban with class : com.linkedin.drelephant.schedulers.AzkabanScheduler
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler oozie with class : com.linkedin.drelephant.schedulers.OozieScheduler
02-18-2019 11:44:16 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Error in checking status of execution: https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0
java.lang.RuntimeException: com.linkedin.drelephant.schedulers.AzkabanScheduler is not a valid Scheduler class.
	at com.linkedin.drelephant.util.InfoExtractor.getWorkflowClientInstance(InfoExtractor.java:287)
	at com.linkedin.drelephant.clients.azkaban.AzkabanJobStatusUtil.getWorkflowClient(AzkabanJobStatusUtil.java:55)
	at com.linkedin.drelephant.clients.azkaban.AzkabanJobStatusUtil.getJobsFromFlow(AzkabanJobStatusUtil.java:99)
	at com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager.analyzeJobExecution(AzkabanJobStatusManager.java:74)
	at com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager.analyzeCompletedJobsExecution(AzkabanJobStatusManager.java:51)
	at com.linkedin.drelephant.tuning.JobStatusManagerTestRunner.testJobStatusAzkaban(JobStatusManagerTestRunner.java:41)
	at com.linkedin.drelephant.tuning.JobStatusManagerTestRunner.run(JobStatusManagerTestRunner.java:30)
	at play.test.Helpers.running(Helpers.java:417)
	at com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
	at sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
	at sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
	at sbt.ForkMain$Run$2.call(ForkMain.java:294)
	at sbt.ForkMain$Run$2.call(ForkMain.java:284)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at com.linkedin.drelephant.util.InfoExtractor.getWorkflowClientInstance(InfoExtractor.java:272)
	... 45 more
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions completed since last iteration: 0
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Execution https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0 is still in running state
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 1
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Adding execution https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0 to fitness computation queue
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 1
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 1
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:44:16 INFO  [pool-40-thread-1] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Creating flow execution for null
02-18-2019 11:44:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.exceptions.EventExceptionTest : correct messagePath is not a file: /data/sample/Sample/Sample/1466675602538-PT-472724050
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 11:44:17 INFO  [Thread-153] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 11:44:17 INFO  [Thread-153] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 11:44:17 INFO  [Thread-153] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 11:44:17 INFO  [Thread-153] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 0
02-18-2019 11:44:17 INFO  [Thread-153] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Baseline Done 
02-18-2019 11:44:17 INFO  [Thread-153] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 11:44:17 INFO  [Thread-153] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 11:44:17 INFO  [Thread-153] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 11:44:17 INFO  [Thread-153] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Baseline Done 
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 11:44:17 INFO  [Thread-153] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Backfill is  enabled
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 11:44:17 INFO  [Thread-154] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 11:44:17 INFO  [Thread-154] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 11:44:17 INFO  [Thread-154] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 11:44:17 INFO  [Thread-154] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 0
02-18-2019 11:44:17 INFO  [Thread-154] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Baseline Done
02-18-2019 11:44:17 INFO  [Thread-154] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false AzkabanJobStatusManager
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 0
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 0
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fitness Computed
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerHBT
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoPSO
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Executing Fitness Manager
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Fitness Computed
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoPSO
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoIPSO
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Executing Fitness Manager
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Fitness Computed
02-18-2019 11:44:17 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoIPSO
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : New parameter suggestion needed for job: countByCountryFlow_countByCountry
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 1
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Getting tuning information for job: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Fetching default parameter values for job https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Adding JobTuningInfo {"jobType":"PIG","tuningJob":{"id":100003,"jobDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","scheduler":"azkaban","username":"mkumar1","jobName":"countByCountryFlow_countByCountry","jobDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","flowDefinition":{"id":10003,"flowDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","flowDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","createdTs":1550470457087,"updatedTs":1550470457087},"createdTs":1518405042000,"updatedTs":1518405043000},"parametersToTune":[{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470457000,"updatedTs":1550470457000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550470457000,"updatedTs":1550470457000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470457000,"updatedTs":1550470457000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550470457000,"updatedTs":1550470457000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470457000,"updatedTs":1550470457000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550470457000,"updatedTs":1550470457000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470457000,"updatedTs":1550470457000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550470457000,"updatedTs":1550470457000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470457000,"updatedTs":1550470457000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550470457000,"updatedTs":1550470457000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470457000,"updatedTs":1550470457000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550470457000,"updatedTs":1550470457000,"isDerived":0}],"tunerState":"{}"}
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Generating Parameters 
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : python /Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py {} [{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470457000,"updatedTs":1550470457000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550470457000,"updatedTs":1550470457000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470457000,"updatedTs":1550470457000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550470457000,"updatedTs":1550470457000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470457000,"updatedTs":1550470457000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550470457000,"updatedTs":1550470457000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470457000,"updatedTs":1550470457000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550470457000,"updatedTs":1550470457000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470457000,"updatedTs":1550470457000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550470457000,"updatedTs":1550470457000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470457000,"updatedTs":1550470457000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550470457000,"updatedTs":1550470457000,"isDerived":0}] PIG 3
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@a485226 fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@62009f5b fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : executor num is 1
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Fetching analytic job list...
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0007
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Lowest finish time retrieved from RM is 2018-05-20 07:06:40.050 GMT for application_1526555215992_0007
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Job queue size is 1
02-18-2019 11:44:17 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Backfilling starts...
02-18-2019 11:44:17 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Jobs fetched for backfill for app type MAPREDUCE and time range: 2018-05-15 15:59:50.000 GMT to 2018-05-20 07:06:40.050 GMT
02-18-2019 11:44:17 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Jobs fetched for backfill for app type SPARK and time range: 2018-05-15 15:59:50.000 GMT to 2018-05-20 07:06:40.050 GMT
02-18-2019 11:44:17 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Jobs fetched for backfill for app type TEZ and time range: 2018-05-15 15:59:50.000 GMT to 2018-05-20 07:06:40.050 GMT
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0007 took 20ms
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0008
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0008 took 1ms
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0003
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0003 took 1ms
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0001
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0001 took 1ms
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0006
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0006 took 0ms
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0002
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0002 took 1ms
02-18-2019 11:44:17 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Finished backfilling jobs for analysis... 6 jobs backfilled. Took 21 ms.
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing TEZ application_1526555215992_0004
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of TEZ application_1526555215992_0004 took 1ms
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing TEZ application_1526555215992_0005
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of TEZ application_1526555215992_0005 took 0ms
02-18-2019 11:44:17 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Main thread is terminated.
02-18-2019 11:44:17 ERROR [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Error in auto tuner thread 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at com.linkedin.drelephant.tuning.AutoTuningFlow.executeFlow(AutoTuningFlow.java:46)
	at com.linkedin.drelephant.AutoTuner.run(AutoTuner.java:58)
	at java.lang.Thread.run(Thread.java:748)
02-18-2019 11:44:17 ERROR [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Error in python script running PSO: [Traceback (most recent call last):,   File "/Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py", line 15, in <module>,     import inspyred, ImportError: No module named inspyred]
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Updating Database
02-18-2019 11:44:17 ERROR [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Suggested parameter suggestion is empty for job id: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:17 WARN  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:17 WARN  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:17 WARN  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:44:17 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:44:17 ERROR [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Error in auto tuner thread 
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at com.linkedin.drelephant.AutoTuner.run(AutoTuner.java:62)
	at java.lang.Thread.run(Thread.java:748)
02-18-2019 11:44:17 INFO  [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Auto tuning thread shutting down
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@474cf504 fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@44916636 fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : executor num is 2
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Fetching analytic job list...
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0001
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Job queue size is 2
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0002
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0001 took 4ms
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0003
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0002 took 11ms
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0004
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0003 took 13ms
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0004 took 6ms
02-18-2019 11:44:17 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Main thread is terminated.
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@1d32f163 fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@727ef330 fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : executor num is 1
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Fetching analytic job list...
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Job queue size is 2
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0001
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0001 took 15ms
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0003
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0003 took 2ms
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0002
02-18-2019 11:44:17 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0002 took 1ms
02-18-2019 11:44:17 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Main thread is terminated.
02-18-2019 11:44:17 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:44:17 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 11:44:17 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 11:44:17 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 11:44:17 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 11:44:17 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 5 job types for 2 app types
02-18-2019 11:44:17 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:44:17 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 11:44:17 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:44:17 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:44:17 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:true, confName:pig.script, confValue:.*.
02-18-2019 11:44:17 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:true, confName:hive.mapred.mode, confValue:.*.
02-18-2019 11:44:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:44:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:44:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : New parameter suggestion needed for job: countByCountryFlow_countByCountry
02-18-2019 11:44:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 1
02-18-2019 11:44:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Getting tuning information for job: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:44:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Fetching default parameter values for job https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:44:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Adding JobTuningInfo {"jobType":"PIG","tuningJob":{"id":100003,"jobDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","scheduler":"azkaban","username":"mkumar1","jobName":"countByCountryFlow_countByCountry","jobDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","flowDefinition":{"id":10003,"flowDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","flowDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","createdTs":1550470458045,"updatedTs":1550470458045},"createdTs":1518405042000,"updatedTs":1518405043000},"parametersToTune":[{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0}],"tunerState":"{}"}
02-18-2019 11:44:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Generating Parameters 
02-18-2019 11:44:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : python /Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py {} [{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0}] PIG 3
02-18-2019 11:44:18 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Error in python script running PSO: [Traceback (most recent call last):,   File "/Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py", line 15, in <module>,     import inspyred, ImportError: No module named inspyred]
02-18-2019 11:44:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Updating Database
02-18-2019 11:44:18 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Suggested parameter suggestion is empty for job id: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:44:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 11:44:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : python /Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py {} [{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550470458000,"updatedTs":1550470458000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550470458000,"updatedTs":1550470458000,"isDerived":0}] PIG 3
02-18-2019 11:44:18 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Error in python script running PSO: [Traceback (most recent call last):,   File "/Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py", line 15, in <module>,     import inspyred, ImportError: No module named inspyred]
02-18-2019 11:44:19 INFO  [play-akka.actor.default-dispatcher-2] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.0.1.Final
02-18-2019 11:44:20 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Parameter set request received from execution: https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmall_countByCountry&attempt=0
02-18-2019 11:44:20 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Creating flow execution for https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmall_countByCountry&attempt=0
02-18-2019 11:44:20 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Tuning Algorithm Type PSO
02-18-2019 11:44:20 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Inserting parameter constraint PSO
02-18-2019 11:44:20 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.obt.OptimizationAlgoFactory : OPTIMIZATION ALGORITHM PSO PIG
02-18-2019 11:44:20 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Not a New Job . Hence check for autoTuninghttps://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmall_countByCountry&attempt=0
02-18-2019 11:44:20 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Not a new Job . Auto Tuning Disabled . Send default parameters
02-18-2019 11:44:20 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Auto Tuning Disabled . Hence no parameter suggestion. Tagging execution with default values
02-18-2019 11:44:20 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Default values {mapreduce.map.memory.mb=2048.0, mapreduce.reduce.memory.mb=2048.0}
02-18-2019 11:44:20 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Marking paramSetID: 2836 SENT
02-18-2019 11:44:20 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Discarding Generated Parameters , as auto tuning off.2
02-18-2019 11:44:20 INFO  [play-akka.actor.default-dispatcher-2] controllers.Application : Output JSON {}
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Parameter set request received from execution: https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmallNew_countByCountry&attempt=0
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Adding new job for tuning, job id: https://elephant.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlowSmallNew&job=countByCountryFlowSmallNew_countByCountry
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Default parameters first time {mapreduce.map.memory.mb=2048.0, mapreduce.reduce.memory.mb=2048.0}
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Version 1	PSO_IPSO
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Added job: https://elephant.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlowSmallNew&job=countByCountryFlowSmallNew_countByCountry for tuning
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Creating flow execution for https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmallNew_countByCountry&attempt=0
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Version 1	PSO_IPSO
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Tuning Algorithm Type PSO_IPSO
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Inserting parameter constraint PSO_IPSO
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.obt.OptimizationAlgoFactory : OPTIMIZATION ALGORITHM PSO_IPSO MR
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  New Job. Hence  Not checking for AutoTuning . Running with default Parameters https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmallNew_countByCountry&attempt=0
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Marking paramSetID: 2836 SENT
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Finishing getCurrentRunParameters
02-18-2019 11:44:21 INFO  [play-akka.actor.default-dispatcher-2] controllers.Application : Output JSON {}
02-18-2019 11:44:23 WARN  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic : Mismatch in the number of files and their corresponding sizes for mapreduce.job.cache.archives
02-18-2019 11:44:23 WARN  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic : Mismatch in the number of files and their corresponding sizes for mapreduce.job.cache.files
02-18-2019 11:44:23 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Could not find 4 threshold levels in 2, 4, 8
02-18-2019 11:44:23 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Could not evaluate 2& in 2&
02-18-2019 11:44:23 WARN  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuration foo2 is negative. Resetting it to 0
02-18-2019 11:44:23 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo4. Value is 0.5. Resetting it to default value: 50
02-18-2019 11:44:23 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo5. Value is 9999999999999999. Resetting it to default value: 50
02-18-2019 11:44:23 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo6. Value is bar. Resetting it to default value: 50
02-18-2019 11:44:23 WARN  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuration foo2 is negative. Resetting it to 0
02-18-2019 11:44:23 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo4. Value is 0.5. Resetting it to default value: 50
02-18-2019 11:44:23 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo6. Value is bar. Resetting it to default value: 50
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Truncating foo-bar to 6 characters for id
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : test_heuristic will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : test_heuristic will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : test_heuristic will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpeedHeuristic : test_heuristic will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpeedHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpillHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpillHeuristic : test_heuristic will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:44:23 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:44:25 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Unable to retrieve the scheduler info for application [application_5678]. It does not contain [spark.driver.extraJavaOptions] property in its spark properties.
02-18-2019 11:44:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : No Scheduler found for appid: application_5678
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: org.apache.oozie.client.$Impl_WorkflowJob@76c4762f
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0004166-160629080632562-oozie-oozi-W
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: workflowJob
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 11:44:26 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 11:44:26 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 11:44:26 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_url_template param for Oozie Scheduler
02-18-2019 11:44:26 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_exec_url_template param for Oozie Scheduler
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: scheduledChildJob
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0163255-160828184536493-oozie-oozie-C@1537
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action is scheduled with coordinator
02-18-2019 11:44:26 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 11:44:26 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 11:44:26 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 11:44:26 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 11:44:26 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_url_template param for Oozie Scheduler
02-18-2019 11:44:26 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_exec_url_template param for Oozie Scheduler
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: scheduledChildJob
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0163255-160828184536493-oozie-oozie-C@1537
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action is scheduled with coordinator
02-18-2019 11:44:26 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 11:44:26 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 11:44:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 11:58:59 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53449/api/v1/applications/application_1
02-18-2019 11:58:59 INFO  [ForkJoinPool-1-worker-13] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53449/api/v1/applications/application_1
02-18-2019 11:58:59 INFO  [ForkJoinPool-1-worker-13] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53449/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 11:59:00 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53455/api/v1/applications/application_1
02-18-2019 11:59:00 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : creating SparkApplication by calling REST API at http://localhost:53455/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 11:59:00 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53457/api/v1/applications/application_1
02-18-2019 11:59:00 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : creating SparkApplication by calling REST API at http://localhost:53457/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 11:59:00 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53459/api/v1/applications/application_1
02-18-2019 11:59:00 INFO  [ForkJoinPool-1-worker-13] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53459/api/v1/applications/application_1
02-18-2019 11:59:00 INFO  [ForkJoinPool-1-worker-15] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53459/api/v1/applications/application_1/logs to get eventlogs
02-18-2019 11:59:00 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53465/api/v1/applications/application_1
02-18-2019 11:59:00 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53470/api/v1/applications?status=completed&minEndDate=2019-02-18T06%3A25%3A40.757GMT&maxEndDate=2019-02-18T06%3A31%3A00.757GMT
02-18-2019 11:59:01 WARN  [pool-1-thread-1-ScalaTest-running-SparkMetricsAggregatorTest] com.linkedin.drelephant.spark.SparkMetricsAggregator : applicationDurationMillis is negative. Skipping Metrics Aggregation:-8000000
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 50.0 MB
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : Replaying Spark logs for application: application_1 withlogPath: webhdfs://nn1.grid.example.com:50070/logs/spark/application_1_1.snappy with codec:Some(org.apache.spark.io.SnappyCompressionCodec@331af11c)
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : Replay completed for application: application_1
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Succeeded fetching data for application_1
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 11:59:01 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 11:59:01 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Succeeded fetching data for application_1
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 11:59:01 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 200.0 MB
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFetcher : appId needs sampling.
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: GMT
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Found job config in intermediate dir: test/resources/history/done_intermediate/user/job_1526555215992_0004_conf.xml
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Found history file in intermediate dir: test/resources/history/done_intermediate/user/job_1526555215992_0004-1526567229183-user-QuasiMonteCarlo-1526567243482-1-1-SUCCEEDED-default-1526567234171.jhist
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: GMT
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:59:02 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@293bae6b fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 11:59:04 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@635a0a5d fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 11:59:04 INFO  [Thread-34] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Starting Auto Tuning thread
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 11:59:04 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : No login user. Creating login user
02-18-2019 11:59:04 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Logging with null and null
02-18-2019 11:59:04 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Logged in with user pkumar2 (auth:SIMPLE)
02-18-2019 11:59:04 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Login is not keytab based
02-18-2019 11:59:04 INFO  [Thread-34] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager HBT
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager OBT
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Azkaban Job Status Manager
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager HBT
02-18-2019 11:59:04 INFO  [Thread-34] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerHBT
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT PSO
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoPSO
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT IPSO
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoIPSO
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT MR
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT Spark
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO MR
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO Spark
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO MR
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO Spark
02-18-2019 11:59:04 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:59:04 ERROR [Thread-34] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 11:59:04 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 11:59:04 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 11:59:04 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 11:59:04 ERROR [Thread-34] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 11:59:04 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 0
02-18-2019 11:59:04 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Baseline Done 
02-18-2019 11:59:04 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 11:59:04 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 11:59:04 INFO  [Thread-35] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 11:59:04 INFO  [Thread-35] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Baseline Done 
02-18-2019 11:59:04 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 11:59:04 INFO  [Thread-36] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 11:59:04 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 11:59:04 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 11:59:04 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 0
02-18-2019 11:59:04 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Baseline Done
02-18-2019 11:59:04 INFO  [Thread-36] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false AzkabanJobStatusManager
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 0
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 0
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fitness Computed
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerHBT
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoPSO
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Executing Fitness Manager
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Fitness Computed
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoPSO
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoIPSO
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Executing Fitness Manager
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Fitness Computed
02-18-2019 11:59:04 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoIPSO
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : No auto-tuning enabled jobs found
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : No auto-tuning enabled jobs found
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : No auto-tuning enabled jobs found
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Param Generation Done
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:04 ERROR [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Error in auto tuner thread 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at com.linkedin.drelephant.tuning.AutoTuningFlow.executeFlow(AutoTuningFlow.java:46)
	at com.linkedin.drelephant.AutoTuner.run(AutoTuner.java:58)
	at java.lang.Thread.run(Thread.java:748)
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : No auto-tuning enabled jobs found
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Param Generation Done
02-18-2019 11:59:04 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 1
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 0
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager HBT
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager OBT
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Azkaban Job Status Manager
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager HBT
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerHBT
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT PSO
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoPSO
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT IPSO
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoIPSO
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT MR
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT Spark
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO MR
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO Spark
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO MR
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO Spark
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-54] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 11:59:05 INFO  [Thread-54] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 11:59:05 INFO  [Thread-54] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 11:59:05 ERROR [Thread-54] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT :  Execution of the base line manager is failed java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT.detectJobsForBaseLineComputation(BaselineManagerHBT.java:28)
	at com.linkedin.drelephant.tuning.AbstractBaselineManager.execute(AbstractBaselineManager.java:58)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 9 more
02-18-2019 11:59:05 INFO  [Thread-54] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 11:59:05 INFO  [Thread-54] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 11:59:05 INFO  [Thread-54] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 11:59:05 ERROR [Thread-54] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT :  Execution of the base line manager is failed java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.BaselineManagerOBT.detectJobsForBaseLineComputation(BaselineManagerOBT.java:32)
	at com.linkedin.drelephant.tuning.AbstractBaselineManager.execute(AbstractBaselineManager.java:58)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 9 more
02-18-2019 11:59:05 INFO  [Thread-54] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 11:59:05 INFO  [Thread-55] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 11:59:05 INFO  [Thread-55] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 11:59:05 INFO  [Thread-55] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 11:59:05 INFO  [Thread-56] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 11:59:05 INFO  [Thread-56] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 11:59:05 INFO  [Thread-56] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:59:05 WARN  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT.getPendingParamSets(ParameterGenerateManagerHBT.java:44)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:59:05 WARN  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT.getPendingParamSets(ParameterGenerateManagerHBT.java:44)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:05 WARN  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:05 WARN  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:05 WARN  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:05 WARN  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : New parameter suggestion needed for job: countByCountryFlow_countByCountry
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 1
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Getting tuning information for job: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Fetching default parameter values for job https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Fetching default parameter values for job 
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Adding JobTuningInfo {"jobType":"PIG","tuningJob":{"id":100003,"jobDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","scheduler":"azkaban","username":"pkumar2","jobName":"countByCountryFlow_countByCountry","jobDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","flowDefinition":{"id":10003,"flowDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","flowDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","createdTs":1550471345443,"updatedTs":1550471345443},"createdTs":1518405042000,"updatedTs":1518405043000},"parametersToTune":[{"id":19,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":4,"jobType":"PIG","optimizationAlgo":"HBT","optimizationAlgoVersion":4,"optimizationMetric":"RESOURCE","createdTs":1550471345000,"updatedTs":1550471345000},"defaultValue":2048.0,"minValue":1024.0,"maxValue":8192.0,"stepSize":1024.0,"createdTs":1550471345000,"updatedTs":1550471345000,"isDerived":0},{"id":20,"paramName":"mapreduce.map.java.opts","tuningAlgorithm":{"id":4,"jobType":"PIG","optimizationAlgo":"HBT","optimizationAlgoVersion":4,"optimizationMetric":"RESOURCE","createdTs":1550471345000,"updatedTs":1550471345000},"defaultValue":1536.0,"minValue":500.0,"maxValue":6144.0,"stepSize":64.0,"createdTs":1550471345000,"updatedTs":1550471345000,"isDerived":0}],"tunerState":"{}"}
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Extract Parameter Information for MR IPSO
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654676&job=overwriter-reminder2&attempt=0
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654677&job=overwriter-reminder2&attempt=0
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values Global 
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  New Suggested Parameter 19	1047.6190476190475
20	427.0

02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.OptimizationAlgoFactory : OPTIMIZATION ALGORITHM PSO_IPSO MR
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl :  IPSO Optimizer
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Extract Parameter Information for MR IPSO
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654676&job=overwriter-reminder2&attempt=0
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654677&job=overwriter-reminder2&attempt=0
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values Global 
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Optimizing Parameter Space  map
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  IPSO for map
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Optimizing Parameter Space  reduce
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  IPSO for reduce
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Constraint Violeted 
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Number of constraint(s) violated: 1
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Constraint Violeted 
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the heuristics values for last run : 
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakUnifiedMemory: 553359
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakJVMUsedMemory: 359326023
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorCore: 2
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : driverMaxPeakJVMUsedMemory: 1051344240
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedSparkDriverMemory: 2147483648
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDriverMemoryOverhead: 0
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMaxExecutors: 900
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMinExecutors: 1
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorInstances: 50
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationEnabled: true
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the suggestions for spark parameters for app id : https://hostname.com:8443/executor?execid=2136899
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorMemory 974861107
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedCore 3
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedMemoryFactor 0.05
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedDriverMemory 1948079095
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorInstances: 34
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the heuristics values for last run : 
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakUnifiedMemory: 553359
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakJVMUsedMemory: 359326023
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorCore: 1
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : driverMaxPeakJVMUsedMemory: 1051344240
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedSparkDriverMemory: 2147483648
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDriverMemoryOverhead: 0
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMaxExecutors: 30
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMinExecutors: 9
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorInstances: null
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationEnabled: true
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the suggestions for spark parameters for app id : https://hostname.com:8443/executor?execid=2136899
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorMemory 1947387940
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedCore 3
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedMemoryFactor 0.05
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedDriverMemory 1948079095
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorInstances: null
02-18-2019 11:59:05 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 11:59:05 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 11:59:05 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 11:59:05 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 0
02-18-2019 11:59:05 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Baseline Done 
02-18-2019 11:59:05 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 11:59:05 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 11:59:05 INFO  [Thread-79] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 11:59:05 INFO  [Thread-79] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Baseline Done 
02-18-2019 11:59:05 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 11:59:05 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 11:59:05 INFO  [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 11:59:05 INFO  [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 11:59:05 INFO  [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 0
02-18-2019 11:59:05 INFO  [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Baseline Done
02-18-2019 11:59:05 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false AzkabanJobStatusManager
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 0
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 0
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fitness Computed
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerHBT
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoPSO
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Executing Fitness Manager
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Fitness Computed
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoPSO
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoIPSO
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Executing Fitness Manager
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 1
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the list of executions completed since last iteration
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Checking current status of started execution: https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Initializing  AzkabanJobStatusUtil
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Fitness Computed
02-18-2019 11:59:05 INFO  [Thread-81] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoIPSO
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : New parameter suggestion needed for job: countByCountryFlow_countByCountry
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 1
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Getting tuning information for job: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file SchedulerConf.xml
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: SchedulerConf.xml
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Fetching default parameter values for job https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Fetching default parameter values for job 
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler airflow with class : com.linkedin.drelephant.schedulers.AirflowScheduler
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler azkaban with class : com.linkedin.drelephant.schedulers.AzkabanScheduler
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler oozie with class : com.linkedin.drelephant.schedulers.OozieScheduler
02-18-2019 11:59:05 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Error in checking status of execution: https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0
java.lang.RuntimeException: com.linkedin.drelephant.schedulers.AzkabanScheduler is not a valid Scheduler class.
	at com.linkedin.drelephant.util.InfoExtractor.getWorkflowClientInstance(InfoExtractor.java:287)
	at com.linkedin.drelephant.clients.azkaban.AzkabanJobStatusUtil.getWorkflowClient(AzkabanJobStatusUtil.java:55)
	at com.linkedin.drelephant.clients.azkaban.AzkabanJobStatusUtil.getJobsFromFlow(AzkabanJobStatusUtil.java:99)
	at com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager.analyzeJobExecution(AzkabanJobStatusManager.java:74)
	at com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager.analyzeCompletedJobsExecution(AzkabanJobStatusManager.java:51)
	at com.linkedin.drelephant.tuning.JobStatusManagerTestRunner.testJobStatusAzkaban(JobStatusManagerTestRunner.java:41)
	at com.linkedin.drelephant.tuning.JobStatusManagerTestRunner.run(JobStatusManagerTestRunner.java:30)
	at play.test.Helpers.running(Helpers.java:417)
	at com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
	at sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
	at sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
	at sbt.ForkMain$Run$2.call(ForkMain.java:294)
	at sbt.ForkMain$Run$2.call(ForkMain.java:284)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at com.linkedin.drelephant.util.InfoExtractor.getWorkflowClientInstance(InfoExtractor.java:272)
	... 45 more
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions completed since last iteration: 0
02-18-2019 11:59:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Execution https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0 is still in running state
02-18-2019 11:59:05 WARN  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
java.lang.RuntimeException: java.lang.IllegalArgumentException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)
 (through reference chain: com.linkedin.drelephant.tuning.JobTuningInfo["parametersToTune"]->com.avaje.ebean.common.BeanList[0]->models.TuningParameter["tuningAlgorithm"]->models.TuningAlgorithm["jobType"])
	at play.libs.Json.toJson(Json.java:32)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsTuningInfo(AbstractParameterGenerateManager.java:179)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:83)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.IllegalArgumentException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)
 (through reference chain: com.linkedin.drelephant.tuning.JobTuningInfo["parametersToTune"]->com.avaje.ebean.common.BeanList[0]->models.TuningParameter["tuningAlgorithm"]->models.TuningAlgorithm["jobType"])
	at com.fasterxml.jackson.databind.ObjectMapper.valueToTree(ObjectMapper.java:2374)
	at play.libs.Json.toJson(Json.java:30)
	... 5 more
Caused by: com.fasterxml.jackson.databind.JsonMappingException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)
 (through reference chain: com.linkedin.drelephant.tuning.JobTuningInfo["parametersToTune"]->com.avaje.ebean.common.BeanList[0]->models.TuningParameter["tuningAlgorithm"]->models.TuningAlgorithm["jobType"])
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:210)
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:177)
	at com.fasterxml.jackson.databind.ser.std.StdSerializer.wrapAndThrow(StdSerializer.java:190)
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:674)
	at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:156)
	at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:575)
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:666)
	at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:156)
	at com.fasterxml.jackson.databind.ser.std.CollectionSerializer.serializeContents(CollectionSerializer.java:132)
	at com.fasterxml.jackson.databind.ser.std.CollectionSerializer.serialize(CollectionSerializer.java:94)
	at com.fasterxml.jackson.databind.ser.std.CollectionSerializer.serialize(CollectionSerializer.java:24)
	at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:575)
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:666)
	at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:156)
	at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:129)
	at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:2242)
	at com.fasterxml.jackson.databind.ObjectMapper.valueToTree(ObjectMapper.java:2369)
	... 6 more
Caused by: javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.core.DefaultBeanLoader.loadBean(DefaultBeanLoader.java:337)
	at com.avaje.ebeaninternal.server.core.DefaultServer.loadBean(DefaultServer.java:514)
	at com.avaje.ebeaninternal.server.loadcontext.DLoadBeanContext.loadBean(DLoadBeanContext.java:184)
	at com.avaje.ebean.bean.EntityBeanIntercept.loadBeanInternal(EntityBeanIntercept.java:512)
	at com.avaje.ebean.bean.EntityBeanIntercept.loadBean(EntityBeanIntercept.java:480)
	at com.avaje.ebean.bean.EntityBeanIntercept.preGetter(EntityBeanIntercept.java:583)
	at models.TuningAlgorithm._ebean_get_jobType(TuningAlgorithm.java:4)
	at models.TuningAlgorithm.getJobType(TuningAlgorithm.java)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:536)
	at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:666)
	... 19 more
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 36 more
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:59:05 WARN  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT.getPendingParamSets(ParameterGenerateManagerHBT.java:44)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:05 WARN  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:05 WARN  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:05 WARN  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:05 WARN  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:05 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:59:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 11:59:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 1
02-18-2019 11:59:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Adding execution https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0 to fitness computation queue
02-18-2019 11:59:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 1
02-18-2019 11:59:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 1
02-18-2019 11:59:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:59:06 INFO  [pool-40-thread-1] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Creating flow execution for null
02-18-2019 11:59:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.exceptions.EventExceptionTest : correct messagePath is not a file: /data/sample/Sample/Sample/1466675602538-PT-472724050
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Backfill is  enabled
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@5d4f276f fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@6235e06c fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : executor num is 1
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Fetching analytic job list...
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0007
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Lowest finish time retrieved from RM is 2018-05-20 07:06:40.050 GMT for application_1526555215992_0007
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Job queue size is 1
02-18-2019 11:59:06 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Backfilling starts...
02-18-2019 11:59:06 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Jobs fetched for backfill for app type MAPREDUCE and time range: 2018-05-15 15:59:50.000 GMT to 2018-05-20 07:06:40.050 GMT
02-18-2019 11:59:06 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Jobs fetched for backfill for app type SPARK and time range: 2018-05-15 15:59:50.000 GMT to 2018-05-20 07:06:40.050 GMT
02-18-2019 11:59:06 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Jobs fetched for backfill for app type TEZ and time range: 2018-05-15 15:59:50.000 GMT to 2018-05-20 07:06:40.050 GMT
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0007 took 19ms
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0008
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0008 took 2ms
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0003
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0003 took 0ms
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0001
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0001 took 0ms
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0006
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0006 took 1ms
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0002
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0002 took 1ms
02-18-2019 11:59:06 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Finished backfilling jobs for analysis... 6 jobs backfilled. Took 20 ms.
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing TEZ application_1526555215992_0004
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of TEZ application_1526555215992_0004 took 0ms
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing TEZ application_1526555215992_0005
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of TEZ application_1526555215992_0005 took 1ms
02-18-2019 11:59:06 INFO  [Thread-153] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 11:59:06 INFO  [Thread-153] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 11:59:06 INFO  [Thread-153] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 11:59:06 INFO  [Thread-153] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 0
02-18-2019 11:59:06 INFO  [Thread-153] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Baseline Done 
02-18-2019 11:59:06 INFO  [Thread-153] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 11:59:06 INFO  [Thread-153] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 11:59:06 INFO  [Thread-153] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 11:59:06 INFO  [Thread-153] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Baseline Done 
02-18-2019 11:59:06 INFO  [Thread-153] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 11:59:06 INFO  [Thread-154] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 11:59:06 INFO  [Thread-154] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 11:59:06 INFO  [Thread-154] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 11:59:06 INFO  [Thread-154] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 0
02-18-2019 11:59:06 INFO  [Thread-154] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Baseline Done
02-18-2019 11:59:06 INFO  [Thread-154] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false AzkabanJobStatusManager
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 0
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 0
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fitness Computed
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerHBT
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoPSO
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Executing Fitness Manager
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Fitness Computed
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoPSO
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoIPSO
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Executing Fitness Manager
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Fitness Computed
02-18-2019 11:59:06 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoIPSO
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : New parameter suggestion needed for job: countByCountryFlow_countByCountry
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 1
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Getting tuning information for job: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Fetching default parameter values for job https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Adding JobTuningInfo {"jobType":"PIG","tuningJob":{"id":100003,"jobDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","scheduler":"azkaban","username":"mkumar1","jobName":"countByCountryFlow_countByCountry","jobDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","flowDefinition":{"id":10003,"flowDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","flowDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","createdTs":1550471346472,"updatedTs":1550471346472},"createdTs":1518405042000,"updatedTs":1518405043000},"parametersToTune":[{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471346000,"updatedTs":1550471346000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550471346000,"updatedTs":1550471346000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471346000,"updatedTs":1550471346000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550471346000,"updatedTs":1550471346000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471346000,"updatedTs":1550471346000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550471346000,"updatedTs":1550471346000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471346000,"updatedTs":1550471346000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550471346000,"updatedTs":1550471346000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471346000,"updatedTs":1550471346000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550471346000,"updatedTs":1550471346000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471346000,"updatedTs":1550471346000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550471346000,"updatedTs":1550471346000,"isDerived":0}],"tunerState":"{}"}
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Generating Parameters 
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : python /Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py {} [{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471346000,"updatedTs":1550471346000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550471346000,"updatedTs":1550471346000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471346000,"updatedTs":1550471346000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550471346000,"updatedTs":1550471346000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471346000,"updatedTs":1550471346000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550471346000,"updatedTs":1550471346000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471346000,"updatedTs":1550471346000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550471346000,"updatedTs":1550471346000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471346000,"updatedTs":1550471346000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550471346000,"updatedTs":1550471346000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471346000,"updatedTs":1550471346000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550471346000,"updatedTs":1550471346000,"isDerived":0}] PIG 3
02-18-2019 11:59:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Main thread is terminated.
02-18-2019 11:59:06 ERROR [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Error in auto tuner thread 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at com.linkedin.drelephant.tuning.AutoTuningFlow.executeFlow(AutoTuningFlow.java:46)
	at com.linkedin.drelephant.AutoTuner.run(AutoTuner.java:58)
	at java.lang.Thread.run(Thread.java:748)
02-18-2019 11:59:06 ERROR [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Error in python script running PSO: [Traceback (most recent call last):,   File "/Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py", line 15, in <module>,     import inspyred, ImportError: No module named inspyred]
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Updating Database
02-18-2019 11:59:06 ERROR [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Suggested parameter suggestion is empty for job id: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:06 WARN  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:06 WARN  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:06 WARN  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 11:59:06 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 11:59:06 ERROR [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Error in auto tuner thread 
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at com.linkedin.drelephant.AutoTuner.run(AutoTuner.java:62)
	at java.lang.Thread.run(Thread.java:748)
02-18-2019 11:59:06 INFO  [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Auto tuning thread shutting down
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@3e527b98 fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@430d80c2 fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : executor num is 2
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Fetching analytic job list...
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0001
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Job queue size is 2
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0002
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0001 took 3ms
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0003
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0002 took 10ms
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0004
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0003 took 12ms
02-18-2019 11:59:06 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0004 took 6ms
02-18-2019 11:59:06 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Main thread is terminated.
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@1a8e3e56 fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@6f22dc08 fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : executor num is 1
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Fetching analytic job list...
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Job queue size is 2
02-18-2019 11:59:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0001
02-18-2019 11:59:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0001 took 14ms
02-18-2019 11:59:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0003
02-18-2019 11:59:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0003 took 2ms
02-18-2019 11:59:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0002
02-18-2019 11:59:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0002 took 1ms
02-18-2019 11:59:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Main thread is terminated.
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 5 job types for 2 app types
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:true, confName:pig.script, confValue:.*.
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:true, confName:hive.mapred.mode, confValue:.*.
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : New parameter suggestion needed for job: countByCountryFlow_countByCountry
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 1
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Getting tuning information for job: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Fetching default parameter values for job https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Adding JobTuningInfo {"jobType":"PIG","tuningJob":{"id":100003,"jobDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","scheduler":"azkaban","username":"mkumar1","jobName":"countByCountryFlow_countByCountry","jobDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","flowDefinition":{"id":10003,"flowDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","flowDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","createdTs":1550471347413,"updatedTs":1550471347413},"createdTs":1518405042000,"updatedTs":1518405043000},"parametersToTune":[{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471347000,"updatedTs":1550471347000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550471347000,"updatedTs":1550471347000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471347000,"updatedTs":1550471347000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550471347000,"updatedTs":1550471347000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471347000,"updatedTs":1550471347000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550471347000,"updatedTs":1550471347000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471347000,"updatedTs":1550471347000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550471347000,"updatedTs":1550471347000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471347000,"updatedTs":1550471347000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550471347000,"updatedTs":1550471347000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471347000,"updatedTs":1550471347000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550471347000,"updatedTs":1550471347000,"isDerived":0}],"tunerState":"{}"}
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Generating Parameters 
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : python /Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py {} [{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471347000,"updatedTs":1550471347000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550471347000,"updatedTs":1550471347000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471347000,"updatedTs":1550471347000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550471347000,"updatedTs":1550471347000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471347000,"updatedTs":1550471347000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550471347000,"updatedTs":1550471347000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471347000,"updatedTs":1550471347000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550471347000,"updatedTs":1550471347000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471347000,"updatedTs":1550471347000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550471347000,"updatedTs":1550471347000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471347000,"updatedTs":1550471347000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550471347000,"updatedTs":1550471347000,"isDerived":0}] PIG 3
02-18-2019 11:59:07 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Error in python script running PSO: [Traceback (most recent call last):,   File "/Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py", line 15, in <module>,     import inspyred, ImportError: No module named inspyred]
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Updating Database
02-18-2019 11:59:07 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Suggested parameter suggestion is empty for job id: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 11:59:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : python /Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py {} [{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471348000,"updatedTs":1550471348000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550471348000,"updatedTs":1550471348000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471348000,"updatedTs":1550471348000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550471348000,"updatedTs":1550471348000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471348000,"updatedTs":1550471348000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550471348000,"updatedTs":1550471348000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471348000,"updatedTs":1550471348000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550471348000,"updatedTs":1550471348000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471348000,"updatedTs":1550471348000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550471348000,"updatedTs":1550471348000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550471348000,"updatedTs":1550471348000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550471348000,"updatedTs":1550471348000,"isDerived":0}] PIG 3
02-18-2019 11:59:07 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Error in python script running PSO: [Traceback (most recent call last):,   File "/Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py", line 15, in <module>,     import inspyred, ImportError: No module named inspyred]
02-18-2019 11:59:08 INFO  [play-akka.actor.default-dispatcher-4] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.0.1.Final
02-18-2019 11:59:10 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Parameter set request received from execution: https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmall_countByCountry&attempt=0
02-18-2019 11:59:10 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Creating flow execution for https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmall_countByCountry&attempt=0
02-18-2019 11:59:10 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Tuning Algorithm Type PSO
02-18-2019 11:59:10 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Inserting parameter constraint PSO
02-18-2019 11:59:10 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.obt.OptimizationAlgoFactory : OPTIMIZATION ALGORITHM PSO PIG
02-18-2019 11:59:10 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Not a New Job . Hence check for autoTuninghttps://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmall_countByCountry&attempt=0
02-18-2019 11:59:10 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Not a new Job . Auto Tuning Disabled . Send default parameters
02-18-2019 11:59:10 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Auto Tuning Disabled . Hence no parameter suggestion. Tagging execution with default values
02-18-2019 11:59:10 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Default values {mapreduce.map.memory.mb=2048.0, mapreduce.reduce.memory.mb=2048.0}
02-18-2019 11:59:10 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Marking paramSetID: 2836 SENT
02-18-2019 11:59:10 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Discarding Generated Parameters , as auto tuning off.2
02-18-2019 11:59:10 INFO  [play-akka.actor.default-dispatcher-2] controllers.Application : Output JSON {}
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Parameter set request received from execution: https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmallNew_countByCountry&attempt=0
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Adding new job for tuning, job id: https://elephant.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlowSmallNew&job=countByCountryFlowSmallNew_countByCountry
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Default parameters first time {mapreduce.map.memory.mb=2048.0, mapreduce.reduce.memory.mb=2048.0}
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Version 1	PSO_IPSO
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Added job: https://elephant.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlowSmallNew&job=countByCountryFlowSmallNew_countByCountry for tuning
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Creating flow execution for https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmallNew_countByCountry&attempt=0
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Version 1	PSO_IPSO
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Tuning Algorithm Type PSO_IPSO
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Inserting parameter constraint PSO_IPSO
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] com.linkedin.drelephant.tuning.obt.OptimizationAlgoFactory : OPTIMIZATION ALGORITHM PSO_IPSO MR
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  New Job. Hence  Not checking for AutoTuning . Running with default Parameters https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmallNew_countByCountry&attempt=0
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Marking paramSetID: 2836 SENT
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Finishing getCurrentRunParameters
02-18-2019 11:59:11 INFO  [play-akka.actor.default-dispatcher-4] controllers.Application : Output JSON {}
02-18-2019 11:59:12 WARN  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic : Mismatch in the number of files and their corresponding sizes for mapreduce.job.cache.archives
02-18-2019 11:59:12 WARN  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic : Mismatch in the number of files and their corresponding sizes for mapreduce.job.cache.files
02-18-2019 11:59:12 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Could not find 4 threshold levels in 2, 4, 8
02-18-2019 11:59:12 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Could not evaluate 2& in 2&
02-18-2019 11:59:12 WARN  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuration foo2 is negative. Resetting it to 0
02-18-2019 11:59:12 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo4. Value is 0.5. Resetting it to default value: 50
02-18-2019 11:59:12 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo5. Value is 9999999999999999. Resetting it to default value: 50
02-18-2019 11:59:12 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo6. Value is bar. Resetting it to default value: 50
02-18-2019 11:59:12 WARN  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuration foo2 is negative. Resetting it to 0
02-18-2019 11:59:12 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo4. Value is 0.5. Resetting it to default value: 50
02-18-2019 11:59:12 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo6. Value is bar. Resetting it to default value: 50
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Truncating foo-bar to 6 characters for id
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : test_heuristic will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : test_heuristic will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : test_heuristic will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpeedHeuristic : test_heuristic will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpeedHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpillHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpillHeuristic : test_heuristic will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 11:59:12 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 11:59:15 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Unable to retrieve the scheduler info for application [application_5678]. It does not contain [spark.driver.extraJavaOptions] property in its spark properties.
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : No Scheduler found for appid: application_5678
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: org.apache.oozie.client.$Impl_WorkflowJob@24941229
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0004166-160629080632562-oozie-oozi-W
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: workflowJob
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 11:59:15 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 11:59:15 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 11:59:15 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_url_template param for Oozie Scheduler
02-18-2019 11:59:15 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_exec_url_template param for Oozie Scheduler
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: scheduledChildJob
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0163255-160828184536493-oozie-oozie-C@1537
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action is scheduled with coordinator
02-18-2019 11:59:15 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 11:59:15 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 11:59:15 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 11:59:15 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 11:59:15 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_url_template param for Oozie Scheduler
02-18-2019 11:59:15 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_exec_url_template param for Oozie Scheduler
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: scheduledChildJob
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0163255-160828184536493-oozie-oozie-C@1537
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action is scheduled with coordinator
02-18-2019 11:59:15 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 11:59:15 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 11:59:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:16:13 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53584/api/v1/applications/application_1
02-18-2019 12:16:13 INFO  [ForkJoinPool-1-worker-13] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53584/api/v1/applications/application_1
02-18-2019 12:16:13 INFO  [ForkJoinPool-1-worker-13] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53584/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 12:16:13 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53590/api/v1/applications/application_1
02-18-2019 12:16:13 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : creating SparkApplication by calling REST API at http://localhost:53590/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 12:16:14 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53592/api/v1/applications/application_1
02-18-2019 12:16:14 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : creating SparkApplication by calling REST API at http://localhost:53592/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 12:16:14 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53594/api/v1/applications/application_1
02-18-2019 12:16:14 INFO  [ForkJoinPool-1-worker-13] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53594/api/v1/applications/application_1
02-18-2019 12:16:14 INFO  [ForkJoinPool-1-worker-7] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53594/api/v1/applications/application_1/logs to get eventlogs
02-18-2019 12:16:14 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53600/api/v1/applications/application_1
02-18-2019 12:16:14 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53605/api/v1/applications?status=completed&minEndDate=2019-02-18T06%3A42%3A54.543GMT&maxEndDate=2019-02-18T06%3A48%3A14.543GMT
02-18-2019 12:16:15 WARN  [pool-1-thread-1-ScalaTest-running-SparkMetricsAggregatorTest] com.linkedin.drelephant.spark.SparkMetricsAggregator : applicationDurationMillis is negative. Skipping Metrics Aggregation:-8000000
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 50.0 MB
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : Replaying Spark logs for application: application_1 withlogPath: webhdfs://nn1.grid.example.com:50070/logs/spark/application_1_1.snappy with codec:Some(org.apache.spark.io.SnappyCompressionCodec@3b178e72)
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : Replay completed for application: application_1
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Succeeded fetching data for application_1
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:16:15 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:16:15 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Succeeded fetching data for application_1
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:16:15 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:16:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 200.0 MB
02-18-2019 12:16:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 12:16:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:16:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:16:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFetcher : appId needs sampling.
02-18-2019 12:16:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:16:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 12:16:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:16:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:16:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:16:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: GMT
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Found job config in intermediate dir: test/resources/history/done_intermediate/user/job_1526555215992_0004_conf.xml
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Found history file in intermediate dir: test/resources/history/done_intermediate/user/job_1526555215992_0004-1526567229183-user-QuasiMonteCarlo-1526567243482-1-1-SUCCEEDED-default-1526567234171.jhist
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: GMT
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:16:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@42f42c2 fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@5e7c051 fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 12:16:18 INFO  [Thread-34] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Starting Auto Tuning thread
02-18-2019 12:16:18 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : No login user. Creating login user
02-18-2019 12:16:18 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Logging with null and null
02-18-2019 12:16:18 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Logged in with user pkumar2 (auth:SIMPLE)
02-18-2019 12:16:18 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Login is not keytab based
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager HBT
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager OBT
02-18-2019 12:16:18 INFO  [Thread-34] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Azkaban Job Status Manager
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager HBT
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerHBT
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT PSO
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoPSO
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT IPSO
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoIPSO
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT MR
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 12:16:18 INFO  [Thread-34] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT Spark
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO MR
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO Spark
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO MR
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO Spark
02-18-2019 12:16:18 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 12:16:18 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 12:16:18 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 12:16:18 ERROR [Thread-34] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:16:18 ERROR [Thread-34] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:16:18 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 0
02-18-2019 12:16:18 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Baseline Done 
02-18-2019 12:16:18 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 12:16:18 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 12:16:18 INFO  [Thread-35] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 12:16:18 INFO  [Thread-35] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Baseline Done 
02-18-2019 12:16:18 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 12:16:18 INFO  [Thread-36] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 12:16:18 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 12:16:18 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 12:16:18 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 0
02-18-2019 12:16:18 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Baseline Done
02-18-2019 12:16:18 INFO  [Thread-36] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false AzkabanJobStatusManager
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 0
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 0
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fitness Computed
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerHBT
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoPSO
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Executing Fitness Manager
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Fitness Computed
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoPSO
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoIPSO
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Executing Fitness Manager
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Fitness Computed
02-18-2019 12:16:18 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoIPSO
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : No auto-tuning enabled jobs found
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:16:18 ERROR [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Error in auto tuner thread 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at com.linkedin.drelephant.tuning.AutoTuningFlow.executeFlow(AutoTuningFlow.java:46)
	at com.linkedin.drelephant.AutoTuner.run(AutoTuner.java:58)
	at java.lang.Thread.run(Thread.java:748)
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : No auto-tuning enabled jobs found
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : No auto-tuning enabled jobs found
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Param Generation Done
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:16:18 WARN  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.api.Play.stop(Play.scala)
 play.test.Helpers.stop(Helpers.java:366)
 controllers.ApplicationTest.stopApp(ApplicationTest.java:66)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.api.Play.stop(Play.scala)
 play.test.Helpers.stop(Helpers.java:366)
 controllers.ApplicationTest.stopApp(ApplicationTest.java:66)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:16:18 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 1
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 0
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager HBT
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager OBT
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Azkaban Job Status Manager
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager HBT
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerHBT
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT PSO
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoPSO
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT IPSO
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoIPSO
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT MR
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT Spark
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO MR
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO Spark
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO MR
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO Spark
02-18-2019 12:16:18 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-54] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 12:16:18 INFO  [Thread-54] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 12:16:18 INFO  [Thread-54] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 12:16:18 ERROR [Thread-54] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT :  Execution of the base line manager is failed java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT.detectJobsForBaseLineComputation(BaselineManagerHBT.java:28)
	at com.linkedin.drelephant.tuning.AbstractBaselineManager.execute(AbstractBaselineManager.java:58)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 9 more
02-18-2019 12:16:18 INFO  [Thread-54] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 12:16:18 INFO  [Thread-54] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 12:16:18 INFO  [Thread-54] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 12:16:18 ERROR [Thread-54] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT :  Execution of the base line manager is failed java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.BaselineManagerOBT.detectJobsForBaseLineComputation(BaselineManagerOBT.java:32)
	at com.linkedin.drelephant.tuning.AbstractBaselineManager.execute(AbstractBaselineManager.java:58)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 9 more
02-18-2019 12:16:18 INFO  [Thread-54] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 12:16:18 INFO  [Thread-55] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 12:16:18 INFO  [Thread-55] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 12:16:18 INFO  [Thread-55] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 12:16:18 INFO  [Thread-56] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 12:16:18 INFO  [Thread-56] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 12:16:18 INFO  [Thread-56] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:16:18 WARN  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT.getPendingParamSets(ParameterGenerateManagerHBT.java:44)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:16:18 WARN  [Thread-57] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT.getPendingParamSets(ParameterGenerateManagerHBT.java:44)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:16:18 WARN  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:16:18 WARN  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:16:18 WARN  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:16:18 WARN  [Thread-57] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testFlowTestRunner(TuningManagerTest.java:79)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:16:18 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : New parameter suggestion needed for job: countByCountryFlow_countByCountry
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 1
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Getting tuning information for job: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Fetching default parameter values for job https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Fetching default parameter values for job 
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Adding JobTuningInfo {"jobType":"PIG","tuningJob":{"id":100003,"jobDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","scheduler":"azkaban","username":"pkumar2","jobName":"countByCountryFlow_countByCountry","jobDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","flowDefinition":{"id":10003,"flowDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","flowDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","createdTs":1550472379017,"updatedTs":1550472379017},"createdTs":1518405042000,"updatedTs":1518405043000},"parametersToTune":[{"id":19,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":4,"jobType":"PIG","optimizationAlgo":"HBT","optimizationAlgoVersion":4,"optimizationMetric":"RESOURCE","createdTs":1550472379000,"updatedTs":1550472379000},"defaultValue":2048.0,"minValue":1024.0,"maxValue":8192.0,"stepSize":1024.0,"createdTs":1550472379000,"updatedTs":1550472379000,"isDerived":0},{"id":20,"paramName":"mapreduce.map.java.opts","tuningAlgorithm":{"id":4,"jobType":"PIG","optimizationAlgo":"HBT","optimizationAlgoVersion":4,"optimizationMetric":"RESOURCE","createdTs":1550472379000,"updatedTs":1550472379000},"defaultValue":1536.0,"minValue":500.0,"maxValue":6144.0,"stepSize":64.0,"createdTs":1550472379000,"updatedTs":1550472379000,"isDerived":0}],"tunerState":"{}"}
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Extract Parameter Information for MR IPSO
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654676&job=overwriter-reminder2&attempt=0
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654677&job=overwriter-reminder2&attempt=0
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values Global 
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  New Suggested Parameter 19	1047.6190476190475
20	427.0

02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.OptimizationAlgoFactory : OPTIMIZATION ALGORITHM PSO_IPSO MR
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl :  IPSO Optimizer
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Extract Parameter Information for MR IPSO
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654676&job=overwriter-reminder2&attempt=0
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654677&job=overwriter-reminder2&attempt=0
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values Global 
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Optimizing Parameter Space  map
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  IPSO for map
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Optimizing Parameter Space  reduce
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  IPSO for reduce
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Constraint Violeted 
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Number of constraint(s) violated: 1
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Constraint Violeted 
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the heuristics values for last run : 
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakUnifiedMemory: 553359
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakJVMUsedMemory: 359326023
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorCore: 2
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : driverMaxPeakJVMUsedMemory: 1051344240
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedSparkDriverMemory: 2147483648
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDriverMemoryOverhead: 0
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMaxExecutors: 900
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMinExecutors: 1
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorInstances: 50
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationEnabled: true
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the suggestions for spark parameters for app id : https://hostname.com:8443/executor?execid=2136899
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorMemory 974861107
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedCore 3
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedMemoryFactor 0.05
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedDriverMemory 1948079095
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorInstances: 34
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the heuristics values for last run : 
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakUnifiedMemory: 553359
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakJVMUsedMemory: 359326023
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorCore: 1
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : driverMaxPeakJVMUsedMemory: 1051344240
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedSparkDriverMemory: 2147483648
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDriverMemoryOverhead: 0
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMaxExecutors: 30
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMinExecutors: 9
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorInstances: null
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationEnabled: true
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the suggestions for spark parameters for app id : https://hostname.com:8443/executor?execid=2136899
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorMemory 1947387940
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedCore 3
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedMemoryFactor 0.05
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedDriverMemory 1948079095
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorInstances: null
02-18-2019 12:16:19 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 12:16:19 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 12:16:19 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 12:16:19 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 1
02-18-2019 12:16:19 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Computing BaseLine
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 1
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the list of executions completed since last iteration
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Checking current status of started execution: https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Initializing  AzkabanJobStatusUtil
02-18-2019 12:16:19 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Updating Database
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file SchedulerConf.xml
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: SchedulerConf.xml
02-18-2019 12:16:19 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Updating Metrics
02-18-2019 12:16:19 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Baseline Done 
02-18-2019 12:16:19 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true BaselineManagerHBT
02-18-2019 12:16:19 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 12:16:19 INFO  [Thread-79] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 12:16:19 INFO  [Thread-79] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Baseline Done 
02-18-2019 12:16:19 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 12:16:19 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 12:16:19 INFO  [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 12:16:19 INFO  [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler airflow with class : com.linkedin.drelephant.schedulers.AirflowScheduler
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler azkaban with class : com.linkedin.drelephant.schedulers.AzkabanScheduler
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler oozie with class : com.linkedin.drelephant.schedulers.OozieScheduler
02-18-2019 12:16:19 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Error in checking status of execution: https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0
java.lang.RuntimeException: com.linkedin.drelephant.schedulers.AzkabanScheduler is not a valid Scheduler class.
	at com.linkedin.drelephant.util.InfoExtractor.getWorkflowClientInstance(InfoExtractor.java:287)
	at com.linkedin.drelephant.clients.azkaban.AzkabanJobStatusUtil.getWorkflowClient(AzkabanJobStatusUtil.java:55)
	at com.linkedin.drelephant.clients.azkaban.AzkabanJobStatusUtil.getJobsFromFlow(AzkabanJobStatusUtil.java:99)
	at com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager.analyzeJobExecution(AzkabanJobStatusManager.java:74)
	at com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager.analyzeCompletedJobsExecution(AzkabanJobStatusManager.java:51)
	at com.linkedin.drelephant.tuning.JobStatusManagerTestRunner.testJobStatusAzkaban(JobStatusManagerTestRunner.java:41)
	at com.linkedin.drelephant.tuning.JobStatusManagerTestRunner.run(JobStatusManagerTestRunner.java:30)
	at play.test.Helpers.running(Helpers.java:417)
	at com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
	at sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
	at sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
	at sbt.ForkMain$Run$2.call(ForkMain.java:294)
	at sbt.ForkMain$Run$2.call(ForkMain.java:284)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at com.linkedin.drelephant.util.InfoExtractor.getWorkflowClientInstance(InfoExtractor.java:272)
	... 45 more
02-18-2019 12:16:19 INFO  [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 1
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions completed since last iteration: 0
02-18-2019 12:16:19 INFO  [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Calculating  Completed Jobs
02-18-2019 12:16:19 INFO  [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the list of executions completed since last iteration
02-18-2019 12:16:19 INFO  [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Checking current status of started execution: https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0
02-18-2019 12:16:19 INFO  [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Initializing  AzkabanJobStatusUtil
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Execution https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0 is still in running state
02-18-2019 12:16:19 ERROR [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Error in checking status of execution: https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0
java.lang.RuntimeException: com.linkedin.drelephant.schedulers.AzkabanScheduler is not a valid Scheduler class.
	at com.linkedin.drelephant.util.InfoExtractor.getWorkflowClientInstance(InfoExtractor.java:287)
	at com.linkedin.drelephant.clients.azkaban.AzkabanJobStatusUtil.getWorkflowClient(AzkabanJobStatusUtil.java:55)
	at com.linkedin.drelephant.clients.azkaban.AzkabanJobStatusUtil.getJobsFromFlow(AzkabanJobStatusUtil.java:99)
	at com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager.analyzeJobExecution(AzkabanJobStatusManager.java:74)
	at com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager.analyzeCompletedJobsExecution(AzkabanJobStatusManager.java:51)
	at com.linkedin.drelephant.tuning.AbstractJobStatusManager.execute(AbstractJobStatusManager.java:121)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at com.linkedin.drelephant.util.InfoExtractor.getWorkflowClientInstance(InfoExtractor.java:272)
	... 7 more
02-18-2019 12:16:19 INFO  [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions completed since last iteration: 0
02-18-2019 12:16:19 INFO  [Thread-80] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Baseline Done
02-18-2019 12:16:19 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false AzkabanJobStatusManager
02-18-2019 12:16:19 INFO  [Thread-81] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 12:16:19 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 12:16:19 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 12:16:19 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 0
02-18-2019 12:16:19 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 12:16:19 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 0
02-18-2019 12:16:19 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 12:16:19 INFO  [Thread-81] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fitness Computed
02-18-2019 12:16:19 INFO  [Thread-81] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerHBT
02-18-2019 12:16:19 INFO  [Thread-81] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoPSO
02-18-2019 12:16:19 INFO  [Thread-81] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Executing Fitness Manager
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:16:19 WARN  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT.getPendingParamSets(ParameterGenerateManagerHBT.java:44)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:16:19 WARN  [Thread-82] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT.getPendingParamSets(ParameterGenerateManagerHBT.java:44)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:16:19 WARN  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:16:19 WARN  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:16:19 WARN  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:16:19 WARN  [Thread-82] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:16:19 INFO  [Thread-82] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 0
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 0
02-18-2019 12:16:19 INFO  [pool-40-thread-1] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Creating flow execution for null
02-18-2019 12:16:19 INFO  [pool-1-thread-1] com.linkedin.drelephant.exceptions.EventExceptionTest : correct messagePath is not a file: /data/sample/Sample/Sample/1466675602538-PT-472724050
02-18-2019 12:16:19 ERROR [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Error in auto tuner thread 
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at com.linkedin.drelephant.AutoTuner.run(AutoTuner.java:62)
	at java.lang.Thread.run(Thread.java:748)
02-18-2019 12:16:19 INFO  [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Auto tuning thread shutting down
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@697626ea fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@6effcf75 fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantRunner : executor num is 2
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantRunner : Fetching analytic job list...
02-18-2019 12:16:20 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0001
02-18-2019 12:16:20 INFO  [Thread-151] com.linkedin.drelephant.ElephantRunner : Job queue size is 2
02-18-2019 12:16:20 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0002
02-18-2019 12:16:20 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0002 took 14ms
02-18-2019 12:16:20 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0003
02-18-2019 12:16:20 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0001 took 17ms
02-18-2019 12:16:20 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0004
02-18-2019 12:16:20 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0003 took 4ms
02-18-2019 12:16:20 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0004 took 2ms
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 5 job types for 2 app types
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:true, confName:pig.script, confValue:.*.
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:true, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : New parameter suggestion needed for job: countByCountryFlow_countByCountry
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 1
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Getting tuning information for job: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Fetching default parameter values for job https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Adding JobTuningInfo {"jobType":"PIG","tuningJob":{"id":100003,"jobDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","scheduler":"azkaban","username":"mkumar1","jobName":"countByCountryFlow_countByCountry","jobDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","flowDefinition":{"id":10003,"flowDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","flowDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","createdTs":1550472380519,"updatedTs":1550472380519},"createdTs":1518405042000,"updatedTs":1518405043000},"parametersToTune":[{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472380000,"updatedTs":1550472380000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550472380000,"updatedTs":1550472380000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472380000,"updatedTs":1550472380000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472380000,"updatedTs":1550472380000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472380000,"updatedTs":1550472380000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550472380000,"updatedTs":1550472380000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472380000,"updatedTs":1550472380000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550472380000,"updatedTs":1550472380000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472380000,"updatedTs":1550472380000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472380000,"updatedTs":1550472380000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472380000,"updatedTs":1550472380000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550472380000,"updatedTs":1550472380000,"isDerived":0}],"tunerState":"{}"}
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Generating Parameters 
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : python /Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py {} [{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472380000,"updatedTs":1550472380000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550472380000,"updatedTs":1550472380000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472380000,"updatedTs":1550472380000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472380000,"updatedTs":1550472380000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472380000,"updatedTs":1550472380000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550472380000,"updatedTs":1550472380000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472380000,"updatedTs":1550472380000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550472380000,"updatedTs":1550472380000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472380000,"updatedTs":1550472380000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472380000,"updatedTs":1550472380000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472380000,"updatedTs":1550472380000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550472380000,"updatedTs":1550472380000,"isDerived":0}] PIG 3
02-18-2019 12:16:20 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Error in python script running PSO: [Traceback (most recent call last):,   File "/Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py", line 15, in <module>,     import inspyred, ImportError: No module named inspyred]
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Updating Database
02-18-2019 12:16:20 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Suggested parameter suggestion is empty for job id: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 12:16:20 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : python /Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py {} [{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472381000,"updatedTs":1550472381000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550472381000,"updatedTs":1550472381000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472381000,"updatedTs":1550472381000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472381000,"updatedTs":1550472381000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472381000,"updatedTs":1550472381000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550472381000,"updatedTs":1550472381000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472381000,"updatedTs":1550472381000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550472381000,"updatedTs":1550472381000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472381000,"updatedTs":1550472381000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472381000,"updatedTs":1550472381000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472381000,"updatedTs":1550472381000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550472381000,"updatedTs":1550472381000,"isDerived":0}] PIG 3
02-18-2019 12:16:20 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Error in python script running PSO: [Traceback (most recent call last):,   File "/Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py", line 15, in <module>,     import inspyred, ImportError: No module named inspyred]
02-18-2019 12:16:21 INFO  [play-akka.actor.default-dispatcher-3] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.0.1.Final
02-18-2019 12:16:23 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Parameter set request received from execution: https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmall_countByCountry&attempt=0
02-18-2019 12:16:23 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Creating flow execution for https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmall_countByCountry&attempt=0
02-18-2019 12:16:23 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Tuning Algorithm Type PSO
02-18-2019 12:16:23 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Inserting parameter constraint PSO
02-18-2019 12:16:23 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.obt.OptimizationAlgoFactory : OPTIMIZATION ALGORITHM PSO PIG
02-18-2019 12:16:23 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Not a New Job . Hence check for autoTuninghttps://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmall_countByCountry&attempt=0
02-18-2019 12:16:23 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Not a new Job . Auto Tuning Disabled . Send default parameters
02-18-2019 12:16:23 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Auto Tuning Disabled . Hence no parameter suggestion. Tagging execution with default values
02-18-2019 12:16:23 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Default values {mapreduce.map.memory.mb=2048.0, mapreduce.reduce.memory.mb=2048.0}
02-18-2019 12:16:23 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Marking paramSetID: 2836 SENT
02-18-2019 12:16:23 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Discarding Generated Parameters , as auto tuning off.2
02-18-2019 12:16:23 INFO  [play-akka.actor.default-dispatcher-3] controllers.Application : Output JSON {}
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Parameter set request received from execution: https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmallNew_countByCountry&attempt=0
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Adding new job for tuning, job id: https://elephant.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlowSmallNew&job=countByCountryFlowSmallNew_countByCountry
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Default parameters first time {mapreduce.map.memory.mb=2048.0, mapreduce.reduce.memory.mb=2048.0}
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Version 1	PSO_IPSO
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Added job: https://elephant.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlowSmallNew&job=countByCountryFlowSmallNew_countByCountry for tuning
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Creating flow execution for https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmallNew_countByCountry&attempt=0
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Version 1	PSO_IPSO
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Tuning Algorithm Type PSO_IPSO
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Inserting parameter constraint PSO_IPSO
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.obt.OptimizationAlgoFactory : OPTIMIZATION ALGORITHM PSO_IPSO MR
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  New Job. Hence  Not checking for AutoTuning . Running with default Parameters https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmallNew_countByCountry&attempt=0
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Marking paramSetID: 2836 SENT
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Finishing getCurrentRunParameters
02-18-2019 12:16:24 INFO  [play-akka.actor.default-dispatcher-2] controllers.Application : Output JSON {}
02-18-2019 12:16:25 WARN  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic : Mismatch in the number of files and their corresponding sizes for mapreduce.job.cache.archives
02-18-2019 12:16:25 WARN  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic : Mismatch in the number of files and their corresponding sizes for mapreduce.job.cache.files
02-18-2019 12:16:25 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Could not find 4 threshold levels in 2, 4, 8
02-18-2019 12:16:25 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Could not evaluate 2& in 2&
02-18-2019 12:16:25 WARN  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuration foo2 is negative. Resetting it to 0
02-18-2019 12:16:25 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo4. Value is 0.5. Resetting it to default value: 50
02-18-2019 12:16:25 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo5. Value is 9999999999999999. Resetting it to default value: 50
02-18-2019 12:16:25 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo6. Value is bar. Resetting it to default value: 50
02-18-2019 12:16:25 WARN  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuration foo2 is negative. Resetting it to 0
02-18-2019 12:16:25 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo4. Value is 0.5. Resetting it to default value: 50
02-18-2019 12:16:25 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo6. Value is bar. Resetting it to default value: 50
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Truncating foo-bar to 6 characters for id
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : test_heuristic will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:16:25 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : test_heuristic will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : test_heuristic will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpeedHeuristic : test_heuristic will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpeedHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpillHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpillHeuristic : test_heuristic will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:16:26 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:16:28 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Unable to retrieve the scheduler info for application [application_5678]. It does not contain [spark.driver.extraJavaOptions] property in its spark properties.
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : No Scheduler found for appid: application_5678
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: org.apache.oozie.client.$Impl_WorkflowJob@3787edc4
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0004166-160629080632562-oozie-oozi-W
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: workflowJob
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:16:28 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 12:16:28 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 12:16:28 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_url_template param for Oozie Scheduler
02-18-2019 12:16:28 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_exec_url_template param for Oozie Scheduler
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: scheduledChildJob
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0163255-160828184536493-oozie-oozie-C@1537
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action is scheduled with coordinator
02-18-2019 12:16:28 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 12:16:28 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:16:28 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 12:16:28 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 12:16:28 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_url_template param for Oozie Scheduler
02-18-2019 12:16:28 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_exec_url_template param for Oozie Scheduler
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: scheduledChildJob
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0163255-160828184536493-oozie-oozie-C@1537
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action is scheduled with coordinator
02-18-2019 12:16:28 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 12:16:28 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 12:16:28 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:18:00 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53650/api/v1/applications/application_1
02-18-2019 12:18:01 INFO  [ForkJoinPool-1-worker-13] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53650/api/v1/applications/application_1
02-18-2019 12:18:01 INFO  [ForkJoinPool-1-worker-1] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53650/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 12:18:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53656/api/v1/applications/application_1
02-18-2019 12:18:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : creating SparkApplication by calling REST API at http://localhost:53656/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 12:18:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53658/api/v1/applications/application_1
02-18-2019 12:18:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : creating SparkApplication by calling REST API at http://localhost:53658/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 12:18:01 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53660/api/v1/applications/application_1
02-18-2019 12:18:01 INFO  [ForkJoinPool-1-worker-13] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53660/api/v1/applications/application_1
02-18-2019 12:18:01 INFO  [ForkJoinPool-1-worker-3] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53660/api/v1/applications/application_1/logs to get eventlogs
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53666/api/v1/applications/application_1
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53671/api/v1/applications?status=completed&minEndDate=2019-02-18T06%3A44%3A42.133GMT&maxEndDate=2019-02-18T06%3A50%3A02.133GMT
02-18-2019 12:18:02 WARN  [pool-1-thread-1-ScalaTest-running-SparkMetricsAggregatorTest] com.linkedin.drelephant.spark.SparkMetricsAggregator : applicationDurationMillis is negative. Skipping Metrics Aggregation:-8000000
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 50.0 MB
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : Replaying Spark logs for application: application_1 withlogPath: webhdfs://nn1.grid.example.com:50070/logs/spark/application_1_1.snappy with codec:Some(org.apache.spark.io.SnappyCompressionCodec@308b0453)
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : Replay completed for application: application_1
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Succeeded fetching data for application_1
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:18:02 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:18:02 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Succeeded fetching data for application_1
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:18:02 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:02 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 200.0 MB
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFetcher : appId needs sampling.
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: GMT
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Found job config in intermediate dir: test/resources/history/done_intermediate/user/job_1526555215992_0004_conf.xml
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Found history file in intermediate dir: test/resources/history/done_intermediate/user/job_1526555215992_0004-1526567229183-user-QuasiMonteCarlo-1526567243482-1-1-SUCCEEDED-default-1526567234171.jhist
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: GMT
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:18:03 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@316cf5f9 fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@4b9773a0 fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 12:18:05 INFO  [Thread-34] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Starting Auto Tuning thread
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:18:05 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : No login user. Creating login user
02-18-2019 12:18:05 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Logging with null and null
02-18-2019 12:18:05 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Logged in with user pkumar2 (auth:SIMPLE)
02-18-2019 12:18:05 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Login is not keytab based
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager HBT
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager OBT
02-18-2019 12:18:05 INFO  [Thread-34] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Azkaban Job Status Manager
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager HBT
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerHBT
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT PSO
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoPSO
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT IPSO
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoIPSO
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT MR
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT Spark
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO MR
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO Spark
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO MR
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO Spark
02-18-2019 12:18:05 INFO  [Auto Tuner Thread] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 12:18:05 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 12:18:05 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 12:18:05 INFO  [Thread-34] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:18:05 ERROR [Thread-34] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:18:05 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 0
02-18-2019 12:18:05 INFO  [Thread-35] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Baseline Done 
02-18-2019 12:18:05 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 12:18:05 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 12:18:05 INFO  [Thread-35] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 12:18:05 ERROR [Thread-34] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:18:05 INFO  [Thread-35] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Baseline Done 
02-18-2019 12:18:05 INFO  [Thread-35] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 12:18:05 INFO  [Thread-36] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 12:18:05 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 12:18:05 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 12:18:05 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 0
02-18-2019 12:18:05 INFO  [Thread-36] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Baseline Done
02-18-2019 12:18:05 INFO  [Thread-36] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false AzkabanJobStatusManager
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 0
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 0
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fitness Computed
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerHBT
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoPSO
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Executing Fitness Manager
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Fitness Computed
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoPSO
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoIPSO
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Executing Fitness Manager
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Fitness Computed
02-18-2019 12:18:05 INFO  [Thread-37] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoIPSO
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:05 ERROR [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Error in auto tuner thread 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at com.linkedin.drelephant.tuning.AutoTuningFlow.executeFlow(AutoTuningFlow.java:46)
	at com.linkedin.drelephant.AutoTuner.run(AutoTuner.java:58)
	at java.lang.Thread.run(Thread.java:748)
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : No auto-tuning enabled jobs found
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 0
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:05 WARN  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.api.Play.stop(Play.scala)
 play.test.Helpers.stop(Helpers.java:366)
 controllers.ApplicationTest.stopApp(ApplicationTest.java:66)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getTuningJobDefinitions(ParameterGenerateManagerOBTAlgoPSOImpl.java:49)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:105)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.api.Play.stop(Play.scala)
 play.test.Helpers.stop(Helpers.java:366)
 controllers.ApplicationTest.stopApp(ApplicationTest.java:66)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:05 WARN  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.api.Play.stop(Play.scala)
 play.test.Helpers.stop(Helpers.java:366)
 controllers.ApplicationTest.stopApp(ApplicationTest.java:66)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.api.Play.stop(Play.scala)
 play.test.Helpers.stop(Helpers.java:366)
 controllers.ApplicationTest.stopApp(ApplicationTest.java:66)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:05 WARN  [Thread-38] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.api.Play.stop(Play.scala)
 play.test.Helpers.stop(Helpers.java:366)
 controllers.ApplicationTest.stopApp(ApplicationTest.java:66)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.api.Play.stop(Play.scala)
 play.test.Helpers.stop(Helpers.java:366)
 controllers.ApplicationTest.stopApp(ApplicationTest.java:66)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:18:05 INFO  [Thread-38] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 1
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 0
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager HBT
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager OBT
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Azkaban Job Status Manager
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager HBT
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerHBT
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT PSO
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoPSO
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT IPSO
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoIPSO
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT MR
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT Spark
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO MR
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO Spark
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO MR
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO Spark
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-55] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 12:18:05 INFO  [Thread-55] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 12:18:05 INFO  [Thread-55] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 12:18:05 ERROR [Thread-55] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT :  Execution of the base line manager is failed Query threw SQLException:Table "TUNING_JOB_DEFINITION" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  


javax.persistence.PersistenceException: Query threw SQLException:Table "TUNING_JOB_DEFINITION" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT.detectJobsForBaseLineComputation(BaselineManagerHBT.java:28)
	at com.linkedin.drelephant.tuning.AbstractBaselineManager.execute(AbstractBaselineManager.java:58)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "TUNING_JOB_DEFINITION" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 9 more
02-18-2019 12:18:05 INFO  [Thread-55] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 12:18:05 INFO  [Thread-55] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 12:18:05 INFO  [Thread-55] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 12:18:05 ERROR [Thread-55] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT :  Execution of the base line manager is failed Query threw SQLException:Table "TUNING_JOB_DEFINITION" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  [42102-196] 
Bind values:[null] 
Query was:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  


javax.persistence.PersistenceException: Query threw SQLException:Table "TUNING_JOB_DEFINITION" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  [42102-196] 
Bind values:[null] 
Query was:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.BaselineManagerOBT.detectJobsForBaseLineComputation(BaselineManagerOBT.java:32)
	at com.linkedin.drelephant.tuning.AbstractBaselineManager.execute(AbstractBaselineManager.java:58)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "TUNING_JOB_DEFINITION" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 9 more
02-18-2019 12:18:05 INFO  [Thread-55] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 12:18:05 INFO  [Thread-56] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 12:18:05 INFO  [Thread-56] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 12:18:05 INFO  [Thread-56] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 12:18:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 12:18:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 12:18:05 INFO  [Thread-57] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:18:05 WARN  [Thread-58] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
javax.persistence.PersistenceException: Query threw SQLException:Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT.getPendingParamSets(ParameterGenerateManagerHBT.java:44)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 11 more
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:18:05 WARN  [Thread-58] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
javax.persistence.PersistenceException: Query threw SQLException:Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT.getPendingParamSets(ParameterGenerateManagerHBT.java:44)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 11 more
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:05 WARN  [Thread-58] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: Query threw SQLException:Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 11 more
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:05 WARN  [Thread-58] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: Query threw SQLException:Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 11 more
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:05 WARN  [Thread-58] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: Query threw SQLException:Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 11 more
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:05 WARN  [Thread-58] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: Query threw SQLException:Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 11 more
02-18-2019 12:18:05 INFO  [Thread-58] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : New parameter suggestion needed for job: countByCountryFlow_countByCountry
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 1
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Getting tuning information for job: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Fetching default parameter values for job https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Fetching default parameter values for job 
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Adding JobTuningInfo {"jobType":"PIG","tuningJob":{"id":100003,"jobDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","scheduler":"azkaban","username":"pkumar2","jobName":"countByCountryFlow_countByCountry","jobDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","flowDefinition":{"id":10003,"flowDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","flowDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","createdTs":1550472485909,"updatedTs":1550472485909},"createdTs":1518405042000,"updatedTs":1518405043000},"parametersToTune":[{"id":19,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":4,"jobType":"PIG","optimizationAlgo":"HBT","optimizationAlgoVersion":4,"optimizationMetric":"RESOURCE","createdTs":1550472486000,"updatedTs":1550472486000},"defaultValue":2048.0,"minValue":1024.0,"maxValue":8192.0,"stepSize":1024.0,"createdTs":1550472486000,"updatedTs":1550472486000,"isDerived":0},{"id":20,"paramName":"mapreduce.map.java.opts","tuningAlgorithm":{"id":4,"jobType":"PIG","optimizationAlgo":"HBT","optimizationAlgoVersion":4,"optimizationMetric":"RESOURCE","createdTs":1550472486000,"updatedTs":1550472486000},"defaultValue":1536.0,"minValue":500.0,"maxValue":6144.0,"stepSize":64.0,"createdTs":1550472486000,"updatedTs":1550472486000,"isDerived":0}],"tunerState":"{}"}
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Extract Parameter Information for MR IPSO
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654676&job=overwriter-reminder2&attempt=0
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654677&job=overwriter-reminder2&attempt=0
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values Global 
02-18-2019 12:18:05 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  New Suggested Parameter 19	1047.6190476190475
20	427.0

02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.OptimizationAlgoFactory : OPTIMIZATION ALGORITHM PSO_IPSO MR
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl :  IPSO Optimizer
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Extract Parameter Information for MR IPSO
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654676&job=overwriter-reminder2&attempt=0
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654677&job=overwriter-reminder2&attempt=0
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values Global 
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Optimizing Parameter Space  map
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  IPSO for map
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Optimizing Parameter Space  reduce
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  IPSO for reduce
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Constraint Violeted 
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Number of constraint(s) violated: 1
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Constraint Violeted 
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the heuristics values for last run : 
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakUnifiedMemory: 553359
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakJVMUsedMemory: 359326023
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorCore: 2
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : driverMaxPeakJVMUsedMemory: 1051344240
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedSparkDriverMemory: 2147483648
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDriverMemoryOverhead: 0
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMaxExecutors: 900
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMinExecutors: 1
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorInstances: 50
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationEnabled: true
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the suggestions for spark parameters for app id : https://hostname.com:8443/executor?execid=2136899
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorMemory 974861107
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedCore 3
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedMemoryFactor 0.05
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedDriverMemory 1948079095
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorInstances: 34
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the heuristics values for last run : 
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakUnifiedMemory: 553359
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakJVMUsedMemory: 359326023
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorCore: 1
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : driverMaxPeakJVMUsedMemory: 1051344240
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedSparkDriverMemory: 2147483648
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDriverMemoryOverhead: 0
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMaxExecutors: 30
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMinExecutors: 9
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorInstances: null
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationEnabled: true
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the suggestions for spark parameters for app id : https://hostname.com:8443/executor?execid=2136899
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorMemory 1947387940
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedCore 3
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedMemoryFactor 0.05
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedDriverMemory 1948079095
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorInstances: null
02-18-2019 12:18:06 INFO  [Thread-77] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 12:18:06 INFO  [Thread-77] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 12:18:06 INFO  [Thread-77] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 12:18:06 ERROR [Thread-77] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT :  Execution of the base line manager is failed Query threw SQLException:Table "TUNING_JOB_DEFINITION" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  


javax.persistence.PersistenceException: Query threw SQLException:Table "TUNING_JOB_DEFINITION" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT.detectJobsForBaseLineComputation(BaselineManagerHBT.java:28)
	at com.linkedin.drelephant.tuning.AbstractBaselineManager.execute(AbstractBaselineManager.java:58)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "TUNING_JOB_DEFINITION" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and t1.optimization_algo = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 9 more
02-18-2019 12:18:06 INFO  [Thread-77] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 12:18:06 INFO  [Thread-77] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 12:18:06 INFO  [Thread-77] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 12:18:06 ERROR [Thread-77] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT :  Execution of the base line manager is failed Query threw SQLException:Table "TUNING_JOB_DEFINITION" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  [42102-196] 
Bind values:[null] 
Query was:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  


javax.persistence.PersistenceException: Query threw SQLException:Table "TUNING_JOB_DEFINITION" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  [42102-196] 
Bind values:[null] 
Query was:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.BaselineManagerOBT.detectJobsForBaseLineComputation(BaselineManagerOBT.java:32)
	at com.linkedin.drelephant.tuning.AbstractBaselineManager.execute(AbstractBaselineManager.java:58)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "TUNING_JOB_DEFINITION" not found; SQL statement:
select t0.client c0, t0.tuning_enabled c1, t0.auto_apply c2, t0.average_resource_usage c3, t0.average_execution_time c4, t0.average_input_size_in_bytes c5, t0.allowed_max_resource_usage_percent c6, t0.allowed_max_execution_time_percent c7, t0.number_of_iterations c8, t0.show_recommendation_count c9, t0.created_ts c10, t0.tuning_disabled_reason c11, t0.updated_ts c12, t0.job_definition_id c13, t0.tuning_algorithm_id c14 from tuning_job_definition t0 left outer join tuning_algorithm t1 on t1.id = t0.tuning_algorithm_id  where t0.average_resource_usage is null  and (t1.optimization_algo = ?  or t1.optimization_algo = ? )  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 9 more
02-18-2019 12:18:06 INFO  [Thread-77] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 12:18:06 INFO  [Thread-78] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 12:18:06 INFO  [Thread-78] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 12:18:06 INFO  [Thread-78] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 12:18:06 INFO  [Thread-79] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 12:18:06 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 12:18:06 INFO  [Thread-79] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:18:06 WARN  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
javax.persistence.PersistenceException: Query threw SQLException:Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT.getPendingParamSets(ParameterGenerateManagerHBT.java:44)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 11 more
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:18:06 WARN  [Thread-80] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Exception in generating parameters 
javax.persistence.PersistenceException: Query threw SQLException:Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT.getPendingParamSets(ParameterGenerateManagerHBT.java:44)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 11 more
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:06 WARN  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: Query threw SQLException:Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 11 more
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:06 WARN  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: Query threw SQLException:Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 11 more
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:06 WARN  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: Query threw SQLException:Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 11 more
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:06 WARN  [Thread-80] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: Query threw SQLException:Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196] 
Bind values:[null] 
Query was:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  


	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:790)
	at com.avaje.ebeaninternal.server.query.CQuery.createPersistenceException(CQuery.java:767)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:202)
	at com.avaje.ebeaninternal.server.query.DefaultOrmQueryEngine.findMany(DefaultOrmQueryEngine.java:77)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.findList(OrmQueryRequest.java:265)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1460)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.h2.jdbc.JdbcSQLException: Table "JOB_SUGGESTED_PARAM_SET" not found; SQL statement:
select t0.id c0, t0.param_set_state c1, t0.is_param_set_default c2, t0.is_param_set_suggested c3, t0.fitness c4, t0.is_param_set_best c5, t0.is_manually_overriden_parameter c6, t0.are_constraints_violated c7, t0.created_ts c8, t0.updated_ts c9, t0.fitness_job_execution_id c10, t0.tuning_algorithm_id c11, t1.id c12, t1.job_def_id c13, t1.scheduler c14, t1.username c15, t1.job_name c16, t1.job_def_url c17, t1.created_ts c18, t1.updated_ts c19, t1.flow_definition_id c20 from job_suggested_param_set t0 left outer join job_definition t1 on t1.id = t0.job_definition_id  left outer join tuning_algorithm t2 on t2.id = t0.tuning_algorithm_id  where ((t0.param_set_state = ?  or t0.param_set_state = ? )  or t0.param_set_state = ? )  and t2.job_type = ?  and t0.is_param_set_best = ?  and t2.optimization_algo = ?  and t0.is_param_set_default = ?  [42102-196]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.get(DbException.java:155)
	at org.h2.command.Parser.readTableOrView(Parser.java:5552)
	at org.h2.command.Parser.readTableFilter(Parser.java:1266)
	at org.h2.command.Parser.parseSelectSimpleFromPart(Parser.java:1946)
	at org.h2.command.Parser.parseSelectSimple(Parser.java:2095)
	at org.h2.command.Parser.parseSelectSub(Parser.java:1940)
	at org.h2.command.Parser.parseSelectUnion(Parser.java:1755)
	at org.h2.command.Parser.parseSelect(Parser.java:1743)
	at org.h2.command.Parser.parsePrepared(Parser.java:449)
	at org.h2.command.Parser.parse(Parser.java:321)
	at org.h2.command.Parser.parse(Parser.java:293)
	at org.h2.command.Parser.prepareCommand(Parser.java:258)
	at org.h2.engine.Session.prepareLocal(Session.java:578)
	at org.h2.engine.Session.prepareCommand(Session.java:519)
	at org.h2.jdbc.JdbcConnection.prepareCommand(JdbcConnection.java:1204)
	at org.h2.jdbc.JdbcPreparedStatement.<init>(JdbcPreparedStatement.java:73)
	at org.h2.jdbc.JdbcConnection.prepareStatement(JdbcConnection.java:288)
	at com.jolbox.bonecp.ConnectionHandle.prepareStatement(ConnectionHandle.java:1024)
	at com.avaje.ebeaninternal.server.query.CQuery.prepareBindExecuteQuery(CQuery.java:360)
	at com.avaje.ebeaninternal.server.query.CQueryEngine.findMany(CQueryEngine.java:162)
	... 11 more
02-18-2019 12:18:06 INFO  [Thread-80] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 1
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the list of executions completed since last iteration
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Checking current status of started execution: https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Initializing  AzkabanJobStatusUtil
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file SchedulerConf.xml
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: SchedulerConf.xml
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler airflow with class : com.linkedin.drelephant.schedulers.AirflowScheduler
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler azkaban with class : com.linkedin.drelephant.schedulers.AzkabanScheduler
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler oozie with class : com.linkedin.drelephant.schedulers.OozieScheduler
02-18-2019 12:18:06 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Error in checking status of execution: https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0
java.lang.RuntimeException: com.linkedin.drelephant.schedulers.AzkabanScheduler is not a valid Scheduler class.
	at com.linkedin.drelephant.util.InfoExtractor.getWorkflowClientInstance(InfoExtractor.java:287)
	at com.linkedin.drelephant.clients.azkaban.AzkabanJobStatusUtil.getWorkflowClient(AzkabanJobStatusUtil.java:55)
	at com.linkedin.drelephant.clients.azkaban.AzkabanJobStatusUtil.getJobsFromFlow(AzkabanJobStatusUtil.java:99)
	at com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager.analyzeJobExecution(AzkabanJobStatusManager.java:74)
	at com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager.analyzeCompletedJobsExecution(AzkabanJobStatusManager.java:51)
	at com.linkedin.drelephant.tuning.JobStatusManagerTestRunner.testJobStatusAzkaban(JobStatusManagerTestRunner.java:41)
	at com.linkedin.drelephant.tuning.JobStatusManagerTestRunner.run(JobStatusManagerTestRunner.java:30)
	at play.test.Helpers.running(Helpers.java:417)
	at com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
	at sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
	at sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
	at sbt.ForkMain$Run$2.call(ForkMain.java:294)
	at sbt.ForkMain$Run$2.call(ForkMain.java:284)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at com.linkedin.drelephant.util.InfoExtractor.getWorkflowClientInstance(InfoExtractor.java:272)
	... 45 more
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions completed since last iteration: 0
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Execution https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0 is still in running state
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 1
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Adding execution https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0 to fitness computation queue
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 1
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 1
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 12:18:06 INFO  [pool-40-thread-1] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Creating flow execution for null
02-18-2019 12:18:06 INFO  [pool-1-thread-1] com.linkedin.drelephant.exceptions.EventExceptionTest : correct messagePath is not a file: /data/sample/Sample/Sample/1466675602538-PT-472724050
02-18-2019 12:18:06 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Backfill is  enabled
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@2204820f fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@433bd0af fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : executor num is 1
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Fetching analytic job list...
02-18-2019 12:18:07 INFO  [Thread-153] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerHBT
02-18-2019 12:18:07 INFO  [Thread-153] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Executing BaseLine
02-18-2019 12:18:07 INFO  [Thread-153] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0007
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Lowest finish time retrieved from RM is 2018-05-20 07:06:40.050 GMT for application_1526555215992_0007
02-18-2019 12:18:07 INFO  [Thread-153] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 0
02-18-2019 12:18:07 INFO  [Thread-153] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Baseline Done 
02-18-2019 12:18:07 INFO  [Thread-153] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerHBT
02-18-2019 12:18:07 INFO  [Thread-153] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  BaselineManagerOBT
02-18-2019 12:18:07 INFO  [Thread-153] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Executing BaseLine
02-18-2019 12:18:07 INFO  [Thread-153] com.linkedin.drelephant.tuning.obt.BaselineManagerOBT : Baseline Done 
02-18-2019 12:18:07 INFO  [Thread-153] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false BaselineManagerOBT
02-18-2019 12:18:07 INFO  [Thread-154] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  AzkabanJobStatusManager
02-18-2019 12:18:07 INFO  [Thread-154] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Executing Job Status Manager
02-18-2019 12:18:07 INFO  [Thread-154] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 12:18:07 INFO  [Thread-154] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 0
02-18-2019 12:18:07 INFO  [Thread-154] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Baseline Done
02-18-2019 12:18:07 INFO  [Thread-154] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false AzkabanJobStatusManager
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerHBT
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Executing Fitness Manager
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Job queue size is 1
02-18-2019 12:18:07 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Backfilling starts...
02-18-2019 12:18:07 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Jobs fetched for backfill for app type MAPREDUCE and time range: 2018-05-15 15:59:50.000 GMT to 2018-05-20 07:06:40.050 GMT
02-18-2019 12:18:07 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Jobs fetched for backfill for app type SPARK and time range: 2018-05-15 15:59:50.000 GMT to 2018-05-20 07:06:40.050 GMT
02-18-2019 12:18:07 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Jobs fetched for backfill for app type TEZ and time range: 2018-05-15 15:59:50.000 GMT to 2018-05-20 07:06:40.050 GMT
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 0
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 0
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fitness Computed
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerHBT
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoPSO
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Executing Fitness Manager
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoPSO : Fitness Computed
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoPSO
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  FitnessManagerOBTAlgoIPSO
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Executing Fitness Manager
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Number of completed execution fetched for fitness computation: 0
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Disable Tuning if Required . Disabled based on number of iteration reached or other terminating conditions for algorithms
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.obt.FitnessManagerOBTAlgoIPSO : Fitness Computed
02-18-2019 12:18:07 INFO  [Thread-155] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true FitnessManagerOBTAlgoIPSO
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerHBT
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0007 took 21ms
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Executing Tuning Algorithm
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0008
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : No auto-tuning enabled jobs found
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0008 took 1ms
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 0
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Param Generation Done
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0003
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerHBT
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0003 took 1ms
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0001
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : New parameter suggestion needed for job: countByCountryFlow_countByCountry
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0001 took 1ms
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 1
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0006
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Getting tuning information for job: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Fetching default parameter values for job https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0006 took 1ms
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0002
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0002 took 1ms
02-18-2019 12:18:07 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Finished backfilling jobs for analysis... 6 jobs backfilled. Took 23 ms.
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing TEZ application_1526555215992_0004
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of TEZ application_1526555215992_0004 took 2ms
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing TEZ application_1526555215992_0005
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of TEZ application_1526555215992_0005 took 5ms
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Adding JobTuningInfo {"jobType":"PIG","tuningJob":{"id":100003,"jobDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","scheduler":"azkaban","username":"mkumar1","jobName":"countByCountryFlow_countByCountry","jobDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","flowDefinition":{"id":10003,"flowDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","flowDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","createdTs":1550472486954,"updatedTs":1550472486954},"createdTs":1518405042000,"updatedTs":1518405043000},"parametersToTune":[{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472487000,"updatedTs":1550472487000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550472487000,"updatedTs":1550472487000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472487000,"updatedTs":1550472487000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472487000,"updatedTs":1550472487000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472487000,"updatedTs":1550472487000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550472487000,"updatedTs":1550472487000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472487000,"updatedTs":1550472487000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550472487000,"updatedTs":1550472487000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472487000,"updatedTs":1550472487000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472487000,"updatedTs":1550472487000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472487000,"updatedTs":1550472487000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550472487000,"updatedTs":1550472487000,"isDerived":0}],"tunerState":"{}"}
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Generating Parameters 
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : python /Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py {} [{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472487000,"updatedTs":1550472487000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550472487000,"updatedTs":1550472487000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472487000,"updatedTs":1550472487000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472487000,"updatedTs":1550472487000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472487000,"updatedTs":1550472487000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550472487000,"updatedTs":1550472487000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472487000,"updatedTs":1550472487000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550472487000,"updatedTs":1550472487000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472487000,"updatedTs":1550472487000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472487000,"updatedTs":1550472487000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472487000,"updatedTs":1550472487000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550472487000,"updatedTs":1550472487000,"isDerived":0}] PIG 3
02-18-2019 12:18:07 INFO  [Thread-152] com.linkedin.drelephant.ElephantRunner : Main thread is terminated.
02-18-2019 12:18:07 ERROR [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Error in auto tuner thread 
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at com.linkedin.drelephant.tuning.AutoTuningFlow.executeFlow(AutoTuningFlow.java:46)
	at com.linkedin.drelephant.AutoTuner.run(AutoTuner.java:58)
	at java.lang.Thread.run(Thread.java:748)
02-18-2019 12:18:07 ERROR [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Error in python script running PSO: [Traceback (most recent call last):,   File "/Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py", line 15, in <module>,     import inspyred, ImportError: No module named inspyred]
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Updating Database
02-18-2019 12:18:07 ERROR [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Suggested parameter suggestion is empty for job id: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager true ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:07 WARN  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOImpl.java:40)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:07 WARN  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Starting Manager  ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:07 WARN  [Thread-156] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl : Exception in generating parameters 
javax.persistence.PersistenceException: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:339)
	at com.avaje.ebeaninternal.server.core.DefaultServer.createQueryTransaction(DefaultServer.java:2018)
	at com.avaje.ebeaninternal.server.core.OrmQueryRequest.initTransIfRequired(OrmQueryRequest.java:178)
	at com.avaje.ebeaninternal.server.core.DefaultServer.findList(DefaultServer.java:1459)
	at com.avaje.ebeaninternal.server.querydefn.DefaultOrmQuery.findList(DefaultOrmQuery.java:885)
	at com.avaje.ebeaninternal.util.DefaultExpressionList.findList(DefaultExpressionList.java:177)
	at com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl.getPendingParamSets(ParameterGenerateManagerOBTAlgoPSOIPSOImpl.java:47)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.getJobsForParamSuggestion(AbstractParameterGenerateManager.java:96)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.detectJobsForParameterGeneration(AbstractParameterGenerateManager.java:82)
	at com.linkedin.drelephant.tuning.AbstractParameterGenerateManager.execute(AbstractParameterGenerateManager.java:146)
	at com.linkedin.drelephant.tuning.AutoTuningFlow$1.run(AutoTuningFlow.java:40)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.sql.SQLException: Attempting to obtain a connection from a pool that has already been shutdown. 
Stack trace of location where pool was shutdown follows:
 java.lang.Thread.getStackTrace(Thread.java:1559)
 com.jolbox.bonecp.BoneCP.captureStackTrace(BoneCP.java:572)
 com.jolbox.bonecp.BoneCP.shutdown(BoneCP.java:161)
 com.jolbox.bonecp.BoneCPDataSource.close(BoneCPDataSource.java:143)
 play.api.db.BoneCPApi.shutdownPool(DB.scala:411)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:264)
 play.api.db.BoneCPPlugin$$anonfun$onStop$1.apply(DB.scala:262)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.db.BoneCPPlugin.onStop(DB.scala:262)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:105)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1$$anonfun$apply$mcV$sp$2.apply(Play.scala:104)
 scala.collection.immutable.List.foreach(List.scala:318)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply$mcV$sp(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.api.Play$$anonfun$stop$1$$anonfun$apply$1.apply(Play.scala:104)
 play.utils.Threads$.withContextClassLoader(Threads.scala:18)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:103)
 play.api.Play$$anonfun$stop$1.apply(Play.scala:102)
 scala.Option.map(Option.scala:145)
 play.api.Play$.stop(Play.scala:102)
 play.core.server.NettyServer.stop(NettyServer.scala:163)
 play.api.test.TestServer.stop(Selenium.scala:155)
 play.test.Helpers.stop(Helpers.java:408)
 play.test.Helpers.running(Helpers.java:419)
 com.linkedin.drelephant.BackfillTest.testBackfillWithDataInDB(BackfillTest.java:258)
 sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 java.lang.reflect.Method.invoke(Method.java:498)
 org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
 org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
 org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
 org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
 org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
 org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
 org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runners.Suite.runChild(Suite.java:128)
 org.junit.runners.Suite.runChild(Suite.java:27)
 org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
 org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
 org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
 org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
 org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
 org.junit.runners.ParentRunner.run(ParentRunner.java:363)
 org.junit.runner.JUnitCore.run(JUnitCore.java:137)
 org.junit.runner.JUnitCore.run(JUnitCore.java:115)
 com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
 sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
 sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
 sbt.ForkMain$Run$2.call(ForkMain.java:294)
 sbt.ForkMain$Run$2.call(ForkMain.java:284)
 java.util.concurrent.FutureTask.run(FutureTask.java:266)
 java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 java.lang.Thread.run(Thread.java:748)

	at com.jolbox.bonecp.AbstractConnectionStrategy.preConnection(AbstractConnectionStrategy.java:52)
	at com.jolbox.bonecp.AbstractConnectionStrategy.getConnection(AbstractConnectionStrategy.java:88)
	at com.jolbox.bonecp.BoneCP.getConnection(BoneCP.java:553)
	at com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:131)
	at play.db.ebean.EbeanPlugin$WrappingDatasource.getConnection(EbeanPlugin.java:147)
	at com.avaje.ebeaninternal.server.transaction.TransactionManager.createQueryTransaction(TransactionManager.java:313)
	... 11 more
02-18-2019 12:18:07 INFO  [Thread-156] com.linkedin.drelephant.tuning.AutoTuningFlow :  Ending Manager false ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:18:07 ERROR [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Error in auto tuner thread 
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at com.linkedin.drelephant.AutoTuner.run(AutoTuner.java:62)
	at java.lang.Thread.run(Thread.java:748)
02-18-2019 12:18:07 INFO  [Auto Tuner Thread] com.linkedin.drelephant.AutoTuner : Auto tuning thread shutting down
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@74642858 fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@5c4aa537 fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : executor num is 2
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Fetching analytic job list...
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0001
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Job queue size is 2
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0002
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0001 took 4ms
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0003
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0002 took 12ms
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0004
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0003 took 12ms
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0004 took 5ms
02-18-2019 12:18:07 INFO  [Thread-171] com.linkedin.drelephant.ElephantRunner : Main thread is terminated.
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@49db5a17 fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@2f6e239e fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : executor num is 1
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Fetching analytic job list...
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Job queue size is 2
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0001
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0001 took 15ms
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0003
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0003 took 1ms
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0002
02-18-2019 12:18:07 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0002 took 2ms
02-18-2019 12:18:07 INFO  [Thread-179] com.linkedin.drelephant.ElephantRunner : Main thread is terminated.
02-18-2019 12:18:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:18:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:18:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:18:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 12:18:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 12:18:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 5 job types for 2 app types
02-18-2019 12:18:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:18:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:18:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:18:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:18:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:true, confName:pig.script, confValue:.*.
02-18-2019 12:18:07 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:true, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:18:08 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Executing Tuning Algorithm
02-18-2019 12:18:08 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Checking which jobs need new parameter suggestion
02-18-2019 12:18:08 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : New parameter suggestion needed for job: countByCountryFlow_countByCountry
02-18-2019 12:18:08 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Number of job(s) which need new parameter suggestion: 1
02-18-2019 12:18:08 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Getting tuning information for job: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:18:08 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Fetching default parameter values for job https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:18:08 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Adding JobTuningInfo {"jobType":"PIG","tuningJob":{"id":100003,"jobDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","scheduler":"azkaban","username":"mkumar1","jobName":"countByCountryFlow_countByCountry","jobDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","flowDefinition":{"id":10003,"flowDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","flowDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","createdTs":1550472487999,"updatedTs":1550472487999},"createdTs":1518405042000,"updatedTs":1518405043000},"parametersToTune":[{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0}],"tunerState":"{}"}
02-18-2019 12:18:08 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Generating Parameters 
02-18-2019 12:18:08 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : python /Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py {} [{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0}] PIG 3
02-18-2019 12:18:08 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Error in python script running PSO: [Traceback (most recent call last):,   File "/Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py", line 15, in <module>,     import inspyred, ImportError: No module named inspyred]
02-18-2019 12:18:08 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Updating Database
02-18-2019 12:18:08 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Suggested parameter suggestion is empty for job id: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:18:08 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Param Generation Done
02-18-2019 12:18:08 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : python /Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py {} [{"id":1,"paramName":"mapreduce.task.io.sort.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":100.0,"minValue":50.0,"maxValue":1920.0,"stepSize":50.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":2,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":3,"paramName":"mapreduce.task.io.sort.factor","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":10.0,"minValue":10.0,"maxValue":150.0,"stepSize":10.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":4,"paramName":"mapreduce.map.sort.spill.percent","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":0.8,"minValue":0.6,"maxValue":0.9,"stepSize":0.1,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":5,"paramName":"mapreduce.reduce.memory.mb","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":2048.0,"minValue":1536.0,"maxValue":8192.0,"stepSize":128.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0},{"id":6,"paramName":"pig.maxCombinedSplitSize","tuningAlgorithm":{"id":1,"jobType":"PIG","optimizationAlgo":"PSO","optimizationAlgoVersion":1,"optimizationMetric":"RESOURCE","createdTs":1550472488000,"updatedTs":1550472488000},"defaultValue":5.36870912E8,"minValue":5.36870912E8,"maxValue":5.36870912E8,"stepSize":128.0,"createdTs":1550472488000,"updatedTs":1550472488000,"isDerived":0}] PIG 3
02-18-2019 12:18:08 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOImpl : Error in python script running PSO: [Traceback (most recent call last):,   File "/Users/pkumar2/Desktop/unifiedarchitecture/unifiedarchitecturev1/dr-elephant/scripts/pso/pso_param_generation.py", line 15, in <module>,     import inspyred, ImportError: No module named inspyred]
02-18-2019 12:18:08 INFO  [play-akka.actor.default-dispatcher-3] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.0.1.Final
02-18-2019 12:18:10 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Parameter set request received from execution: https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmall_countByCountry&attempt=0
02-18-2019 12:18:10 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Creating flow execution for https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmall_countByCountry&attempt=0
02-18-2019 12:18:10 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Tuning Algorithm Type PSO
02-18-2019 12:18:10 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Inserting parameter constraint PSO
02-18-2019 12:18:10 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.obt.OptimizationAlgoFactory : OPTIMIZATION ALGORITHM PSO PIG
02-18-2019 12:18:10 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Not a New Job . Hence check for autoTuninghttps://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmall_countByCountry&attempt=0
02-18-2019 12:18:10 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Not a new Job . Auto Tuning Disabled . Send default parameters
02-18-2019 12:18:10 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Auto Tuning Disabled . Hence no parameter suggestion. Tagging execution with default values
02-18-2019 12:18:10 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Default values {mapreduce.map.memory.mb=2048.0, mapreduce.reduce.memory.mb=2048.0}
02-18-2019 12:18:10 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Marking paramSetID: 2836 SENT
02-18-2019 12:18:10 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Discarding Generated Parameters , as auto tuning off.2
02-18-2019 12:18:10 INFO  [play-akka.actor.default-dispatcher-3] controllers.Application : Output JSON {}
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Parameter set request received from execution: https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmallNew_countByCountry&attempt=0
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Adding new job for tuning, job id: https://elephant.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlowSmallNew&job=countByCountryFlowSmallNew_countByCountry
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Default parameters first time {mapreduce.map.memory.mb=2048.0, mapreduce.reduce.memory.mb=2048.0}
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Version 1	PSO_IPSO
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Added job: https://elephant.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlowSmallNew&job=countByCountryFlowSmallNew_countByCountry for tuning
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Creating flow execution for https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmallNew_countByCountry&attempt=0
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Version 1	PSO_IPSO
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  Tuning Algorithm Type PSO_IPSO
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Inserting parameter constraint PSO_IPSO
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.obt.OptimizationAlgoFactory : OPTIMIZATION ALGORITHM PSO_IPSO MR
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper :  New Job. Hence  Not checking for AutoTuning . Running with default Parameters https://elephant.linkedin.com:8443/executor?execid=5221700&job=countByCountryFlowSmallNew_countByCountry&attempt=0
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Marking paramSetID: 2836 SENT
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Finishing getCurrentRunParameters
02-18-2019 12:18:11 INFO  [play-akka.actor.default-dispatcher-3] controllers.Application : Output JSON {}
02-18-2019 12:18:13 WARN  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic : Mismatch in the number of files and their corresponding sizes for mapreduce.job.cache.archives
02-18-2019 12:18:13 WARN  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic : Mismatch in the number of files and their corresponding sizes for mapreduce.job.cache.files
02-18-2019 12:18:13 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Could not find 4 threshold levels in 2, 4, 8
02-18-2019 12:18:13 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Could not evaluate 2& in 2&
02-18-2019 12:18:13 WARN  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuration foo2 is negative. Resetting it to 0
02-18-2019 12:18:13 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo4. Value is 0.5. Resetting it to default value: 50
02-18-2019 12:18:13 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo5. Value is 9999999999999999. Resetting it to default value: 50
02-18-2019 12:18:13 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo6. Value is bar. Resetting it to default value: 50
02-18-2019 12:18:13 WARN  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuration foo2 is negative. Resetting it to 0
02-18-2019 12:18:13 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo4. Value is 0.5. Resetting it to default value: 50
02-18-2019 12:18:13 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo6. Value is bar. Resetting it to default value: 50
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Truncating foo-bar to 6 characters for id
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : test_heuristic will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : test_heuristic will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : test_heuristic will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpeedHeuristic : test_heuristic will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpeedHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpillHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpillHeuristic : test_heuristic will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:18:13 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:18:15 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Unable to retrieve the scheduler info for application [application_5678]. It does not contain [spark.driver.extraJavaOptions] property in its spark properties.
02-18-2019 12:18:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : No Scheduler found for appid: application_5678
02-18-2019 12:18:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:18:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: org.apache.oozie.client.$Impl_WorkflowJob@6cbeeb7
02-18-2019 12:18:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0004166-160629080632562-oozie-oozi-W
02-18-2019 12:18:15 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: workflowJob
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:18:16 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 12:18:16 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 12:18:16 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_url_template param for Oozie Scheduler
02-18-2019 12:18:16 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_exec_url_template param for Oozie Scheduler
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: scheduledChildJob
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0163255-160828184536493-oozie-oozie-C@1537
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action is scheduled with coordinator
02-18-2019 12:18:16 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 12:18:16 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:18:16 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 12:18:16 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 12:18:16 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_url_template param for Oozie Scheduler
02-18-2019 12:18:16 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_exec_url_template param for Oozie Scheduler
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: scheduledChildJob
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0163255-160828184536493-oozie-oozie-C@1537
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action is scheduled with coordinator
02-18-2019 12:18:16 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 12:18:16 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 12:18:16 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:23:30 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53746/api/v1/applications/application_1
02-18-2019 12:23:30 INFO  [ForkJoinPool-1-worker-13] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53746/api/v1/applications/application_1
02-18-2019 12:23:30 INFO  [ForkJoinPool-1-worker-13] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53746/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 12:23:30 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53751/api/v1/applications/application_1
02-18-2019 12:23:31 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : creating SparkApplication by calling REST API at http://localhost:53751/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 12:23:31 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53753/api/v1/applications/application_1
02-18-2019 12:23:31 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : creating SparkApplication by calling REST API at http://localhost:53753/api/v1/applications/application_1/2/logs to get eventlogs
02-18-2019 12:23:31 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53755/api/v1/applications/application_1
02-18-2019 12:23:31 INFO  [ForkJoinPool-1-worker-5] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53755/api/v1/applications/application_1
02-18-2019 12:23:31 INFO  [ForkJoinPool-1-worker-3] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53755/api/v1/applications/application_1/logs to get eventlogs
02-18-2019 12:23:31 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53761/api/v1/applications/application_1
02-18-2019 12:23:31 INFO  [pool-1-thread-1-ScalaTest-running-SparkRestClientTest] com.linkedin.drelephant.spark.fetchers.SparkRestClient : calling REST API at http://localhost:53766/api/v1/applications?status=completed&minEndDate=2019-02-18T06%3A50%3A11.488GMT&maxEndDate=2019-02-18T06%3A55%3A31.488GMT
02-18-2019 12:23:32 WARN  [pool-1-thread-1-ScalaTest-running-SparkMetricsAggregatorTest] com.linkedin.drelephant.spark.SparkMetricsAggregator : applicationDurationMillis is negative. Skipping Metrics Aggregation:-8000000
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 50.0 MB
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log limit of Spark application is set to 100.0 MB
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : Replaying Spark logs for application: application_1 withlogPath: webhdfs://nn1.grid.example.com:50070/logs/spark/application_1_1.snappy with codec:Some(org.apache.spark.io.SnappyCompressionCodec@501d0620)
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFsFetcherTest] org.apache.spark.deploy.history.SparkFSFetcher$ : Replay completed for application: application_1
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Succeeded fetching data for application_1
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:23:32 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:23:32 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Succeeded fetching data for application_1
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Fetching data for application_1
02-18-2019 12:23:32 WARN  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : Failed fetching data for application_1. I will retry after some time! Exception Message is: null
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1-ScalaTest-running-SparkFetcherTest] com.linkedin.drelephant.spark.fetchers.SparkFetcher : The event log location of Spark application is set to None
02-18-2019 12:23:32 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 200.0 MB
02-18-2019 12:23:32 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 12:23:32 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:23:32 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:23:32 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFetcher : appId needs sampling.
02-18-2019 12:23:32 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:23:32 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 12:23:32 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:23:32 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:23:32 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:23:32 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: GMT
02-18-2019 12:23:32 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:23:32 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Found job config in intermediate dir: test/resources/history/done_intermediate/user/job_1526555215992_0004_conf.xml
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Found history file in intermediate dir: test/resources/history/done_intermediate/user/job_1526555215992_0004-1526567229183-user-QuasiMonteCarlo-1526567243482-1-1-SUCCEEDED-default-1526567234171.jhist
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: GMT
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: Asia/Kolkata
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:23:33 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@309355b7 fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 12:23:34 INFO  [pool-1-thread-1] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@7c825976 fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 12:23:34 INFO  [Thread-34] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:34 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : No login user. Creating login user
02-18-2019 12:23:34 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Logging with null and null
02-18-2019 12:23:34 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Logged in with user pkumar2 (auth:SIMPLE)
02-18-2019 12:23:34 INFO  [Thread-34] com.linkedin.drelephant.security.HadoopSecurity : Login is not keytab based
02-18-2019 12:23:34 INFO  [Thread-34] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:34 INFO  [Thread-34] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:34 ERROR [Thread-34] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:23:34 ERROR [Thread-34] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 1
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Fetching jobs for HBT which baseline metrics need to be computed
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.BaselineManagerHBT : Total jobs for Baseline Computation in HBT 0
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager HBT
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Base line Manager OBT
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Azkaban Job Status Manager
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager HBT
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerHBT
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT PSO
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoPSO
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type Fitness Manager OBT IPSO
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading FitnessManagerOBTAlgoIPSO
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT MR
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager HBT Spark
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerHBT
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO MR
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplMRExecutionEngine
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT PSO Spark
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOImplSparkExecutionEngine
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO MR
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplMRExecutionEngine
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.ManagerFactory : Manager Type TuningType Manager OBT IPSO Spark
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.AutoTuningFlow : Loading ParameterGenerateManagerOBTAlgoPSOIPSOImplSparkExecutionEngine
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Checking which jobs need new parameter suggestion
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : New parameter suggestion needed for job: countByCountryFlow_countByCountry
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Number of job(s) which need new parameter suggestion: 1
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Getting tuning information for job: https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Fetching default parameter values for job https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Fetching default parameter values for job 
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.ParameterGenerateManagerHBT : Adding JobTuningInfo {"jobType":"PIG","tuningJob":{"id":100003,"jobDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","scheduler":"azkaban","username":"pkumar2","jobName":"countByCountryFlow_countByCountry","jobDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow&job=countByCountryFlow_countByCountry","flowDefinition":{"id":10003,"flowDefId":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","flowDefUrl":"https://ltx1-holdemaz01.grid.linkedin.com:8443/manager?project=AzkabanHelloPigTest&flow=countByCountryFlow","createdTs":1550472815521,"updatedTs":1550472815521},"createdTs":1518405042000,"updatedTs":1518405043000},"parametersToTune":[{"id":19,"paramName":"mapreduce.map.memory.mb","tuningAlgorithm":{"id":4,"jobType":"PIG","optimizationAlgo":"HBT","optimizationAlgoVersion":4,"optimizationMetric":"RESOURCE","createdTs":1550472815000,"updatedTs":1550472815000},"defaultValue":2048.0,"minValue":1024.0,"maxValue":8192.0,"stepSize":1024.0,"createdTs":1550472816000,"updatedTs":1550472816000,"isDerived":0},{"id":20,"paramName":"mapreduce.map.java.opts","tuningAlgorithm":{"id":4,"jobType":"PIG","optimizationAlgo":"HBT","optimizationAlgoVersion":4,"optimizationMetric":"RESOURCE","createdTs":1550472815000,"updatedTs":1550472815000},"defaultValue":1536.0,"minValue":500.0,"maxValue":6144.0,"stepSize":64.0,"createdTs":1550472816000,"updatedTs":1550472816000,"isDerived":0}],"tunerState":"{}"}
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Extract Parameter Information for MR IPSO
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654676&job=overwriter-reminder2&attempt=0
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654677&job=overwriter-reminder2&attempt=0
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values Global 
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  New Suggested Parameter 19	1047.6190476190475
20	427.0

02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.OptimizationAlgoFactory : OPTIMIZATION ALGORITHM PSO_IPSO MR
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.obt.ParameterGenerateManagerOBTAlgoPSOIPSOImpl :  IPSO Optimizer
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Extract Parameter Information for MR IPSO
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654676&job=overwriter-reminder2&attempt=0
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values local   https://elephant.linkedin.com:8443/executor?execid=1654677&job=overwriter-reminder2&attempt=0
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Usage Values Global 
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Optimizing Parameter Space  map
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  IPSO for map
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Optimizing Parameter Space  reduce
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  IPSO for reduce
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Constraint Violeted 
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine : Number of constraint(s) violated: 1
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.MRExecutionEngine :  Constraint Violeted 
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the heuristics values for last run : 
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakUnifiedMemory: 553359
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakJVMUsedMemory: 359326023
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorCore: 2
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : driverMaxPeakJVMUsedMemory: 1051344240
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedSparkDriverMemory: 2147483648
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDriverMemoryOverhead: 0
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMaxExecutors: 900
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMinExecutors: 1
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorInstances: 50
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationEnabled: true
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the suggestions for spark parameters for app id : https://hostname.com:8443/executor?execid=2136899
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorMemory 974861107
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedCore 3
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedMemoryFactor 0.05
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedDriverMemory 1948079095
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorInstances: 34
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the heuristics values for last run : 
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakUnifiedMemory: 553359
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : maxPeakJVMUsedMemory: 359326023
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorCore: 1
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : driverMaxPeakJVMUsedMemory: 1051344240
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedSparkDriverMemory: 2147483648
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDriverMemoryOverhead: 0
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMaxExecutors: 30
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationMinExecutors: 9
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunExecutorInstances: null
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : lastRunDynamicAllocationEnabled: true
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : Following are the suggestions for spark parameters for app id : https://hostname.com:8443/executor?execid=2136899
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorMemory 1947387940
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedCore 3
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedMemoryFactor 0.05
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedDriverMemory 1948079095
02-18-2019 12:23:35 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.engine.SparkHBTParamRecommender : suggestedExecutorInstances: null
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the executions which are in progress
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions which are in progress: 1
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Fetching the list of executions completed since last iteration
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Checking current status of started execution: https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Initializing  AzkabanJobStatusUtil
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Loading configuration file SchedulerConf.xml
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: SchedulerConf.xml
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler airflow with class : com.linkedin.drelephant.schedulers.AirflowScheduler
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler azkaban with class : com.linkedin.drelephant.schedulers.AzkabanScheduler
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Load Scheduler oozie with class : com.linkedin.drelephant.schedulers.OozieScheduler
02-18-2019 12:23:36 ERROR [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Error in checking status of execution: https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0
java.lang.RuntimeException: com.linkedin.drelephant.schedulers.AzkabanScheduler is not a valid Scheduler class.
	at com.linkedin.drelephant.util.InfoExtractor.getWorkflowClientInstance(InfoExtractor.java:287)
	at com.linkedin.drelephant.clients.azkaban.AzkabanJobStatusUtil.getWorkflowClient(AzkabanJobStatusUtil.java:55)
	at com.linkedin.drelephant.clients.azkaban.AzkabanJobStatusUtil.getJobsFromFlow(AzkabanJobStatusUtil.java:99)
	at com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager.analyzeJobExecution(AzkabanJobStatusManager.java:74)
	at com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager.analyzeCompletedJobsExecution(AzkabanJobStatusManager.java:51)
	at com.linkedin.drelephant.tuning.JobStatusManagerTestRunner.testJobStatusAzkaban(JobStatusManagerTestRunner.java:41)
	at com.linkedin.drelephant.tuning.JobStatusManagerTestRunner.run(JobStatusManagerTestRunner.java:30)
	at play.test.Helpers.running(Helpers.java:417)
	at com.linkedin.drelephant.tuning.TuningManagerTest.testJobStatusManagerTestRunner(TuningManagerTest.java:89)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:27)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at com.novocode.junit.JUnitRunner.run(JUnitRunner.java:90)
	at sbt.RunnerWrapper$1.runRunner2(FrameworkWrapper.java:223)
	at sbt.RunnerWrapper$1.execute(FrameworkWrapper.java:236)
	at sbt.ForkMain$Run$2.call(ForkMain.java:294)
	at sbt.ForkMain$Run$2.call(ForkMain.java:284)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.NullPointerException
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at com.linkedin.drelephant.util.InfoExtractor.getWorkflowClientInstance(InfoExtractor.java:272)
	... 45 more
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Number of executions completed since last iteration: 0
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.Schduler.AzkabanJobStatusManager : Execution https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0 is still in running state
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Fetching completed executions whose fitness are yet to be computed
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : #completed executions whose metrics are not computed: 1
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Adding execution https://ltx1-holdemaz01.grid.linkedin.com:8443/executor?execid=5416293&job=countByCountryFlow_countByCountry&attempt=0 to fitness computation queue
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 1
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT :  Final jobs for fitness Computation 1
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.tuning.hbt.FitnessManagerHBT : Number of completed execution fetched for fitness computation: 0
02-18-2019 12:23:36 INFO  [pool-40-thread-1] com.linkedin.drelephant.tuning.AutoTuningAPIHelper : Creating flow execution for null
02-18-2019 12:23:36 INFO  [pool-1-thread-1] com.linkedin.drelephant.exceptions.EventExceptionTest : correct messagePath is not a file: /data/sample/Sample/Sample/1466675602538-PT-472724050
02-18-2019 12:23:36 INFO  [Thread-139] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:36 INFO  [Thread-139] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:36 INFO  [Thread-139] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:36 ERROR [Thread-139] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:23:36 ERROR [Thread-139] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantRunner : Backfill is  enabled
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@476daeb9 fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@704e338e fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantRunner : executor num is 1
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantRunner : Fetching analytic job list...
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0007
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantRunner : Lowest finish time retrieved from RM is 2018-05-20 07:06:40.050 GMT for application_1526555215992_0007
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantRunner : Job queue size is 1
02-18-2019 12:23:36 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Backfilling starts...
02-18-2019 12:23:36 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Jobs fetched for backfill for app type MAPREDUCE and time range: 2018-05-15 15:59:50.000 GMT to 2018-05-20 07:06:40.050 GMT
02-18-2019 12:23:36 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Jobs fetched for backfill for app type SPARK and time range: 2018-05-15 15:59:50.000 GMT to 2018-05-20 07:06:40.050 GMT
02-18-2019 12:23:36 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Jobs fetched for backfill for app type TEZ and time range: 2018-05-15 15:59:50.000 GMT to 2018-05-20 07:06:40.050 GMT
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0007 took 21ms
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0008
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0008 took 1ms
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0003
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0003 took 1ms
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0001
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0001 took 1ms
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0006
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0006 took 0ms
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0002
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0002 took 0ms
02-18-2019 12:23:36 INFO  [Backfill Thread] com.linkedin.drelephant.ElephantRunner : Finished backfilling jobs for analysis... 6 jobs backfilled. Took 19 ms.
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing TEZ application_1526555215992_0004
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of TEZ application_1526555215992_0004 took 1ms
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing TEZ application_1526555215992_0005
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of TEZ application_1526555215992_0005 took 0ms
02-18-2019 12:23:36 INFO  [Thread-140] com.linkedin.drelephant.ElephantRunner : Main thread is terminated.
02-18-2019 12:23:36 INFO  [Thread-147] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:36 INFO  [Thread-147] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:36 INFO  [Thread-147] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:36 ERROR [Thread-147] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:23:36 ERROR [Thread-147] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:23:36 INFO  [Thread-154] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:36 INFO  [Thread-154] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:36 INFO  [Thread-154] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 12:23:36 ERROR [Thread-154] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:23:36 ERROR [Thread-154] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@116da5e7 fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@28324bfa fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantRunner : executor num is 2
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantRunner : Fetching analytic job list...
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0001
02-18-2019 12:23:36 INFO  [Thread-155] com.linkedin.drelephant.ElephantRunner : Job queue size is 2
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0002
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0001 took 4ms
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0003
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0002 took 11ms
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0004
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0003 took 12ms
02-18-2019 12:23:36 INFO  [dr-el-executor-thread-1] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0004 took 5ms
02-18-2019 12:23:37 INFO  [Thread-155] com.linkedin.drelephant.ElephantRunner : Main thread is terminated.
02-18-2019 12:23:37 INFO  [Thread-162] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:37 INFO  [Thread-162] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:37 INFO  [Thread-162] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:37 ERROR [Thread-162] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:23:37 ERROR [Thread-162] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.util.Utils : Loading configuration file AggregatorConf.xml
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: AggregatorConf.xml
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.mapreduce.MapReduceMetricsAggregator
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Aggregator : com.linkedin.drelephant.spark.SparkMetricsAggregator
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.util.Utils : Loading configuration file FetcherConf.xml
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: FetcherConf.xml
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : The history log limit of MapReduce application is set to 500.0 MB
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Using timezone: PST
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : Intermediate history dir: test/resources/history/done_intermediate
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2 : History done dir: test/resources/history/done
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Fetcher : com.linkedin.drelephant.spark.fetchers.FSFetcher
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.util.Utils : Loading configuration file HeuristicConf.xml
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: HeuristicConf.xml
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Mapper Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSkew
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Mapper GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : Mapper Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperTime
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : Mapper Speed will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpeed
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : Mapper Spill will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperSpill
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Mapper Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpMapperMemory
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : Reducer Skew will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerSkew
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : Reducer GC will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpGC
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : Reducer Time will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerTime
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : Reducer Memory will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpReducerMemory
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : Shuffle & Sort will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpShuffleSort
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpException
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.mapreduce.helpDistributedCacheLimit
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpConfigurationHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorsHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.JobsHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpJobsHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.StagesHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpStagesHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load Heuristic : com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Load View : views.html.help.spark.helpExecutorGcHeuristic
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.util.Utils : Loading configuration file JobTypeConf.xml
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.util.Utils : Configuation file loaded. File: JobTypeConf.xml
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:OozieLauncher, for application type:mapreduce, isDefault:false, confName:oozie.launcher.action.main.class, confValue:.*.
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Voldemort, for application type:mapreduce, isDefault:false, confName:mapred.reducer.class, confValue:voldemort.store.readonly.mr.*.
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Kafka, for application type:mapreduce, isDefault:false, confName:kafka.url, confValue:.*.
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 8 job types for 2 app types
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Loading configuration file GeneralConf.xml
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Loading configuration file AutoTuningConf.xml
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Configuring ElephantContext...
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Supports SPARK application type, using com.linkedin.drelephant.spark.fetchers.FSFetcher@21c7e50c fetcher class with Heuristics [com.linkedin.drelephant.spark.heuristics.ConfigurationHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorsHeuristic, com.linkedin.drelephant.spark.heuristics.JobsHeuristic, com.linkedin.drelephant.spark.heuristics.StagesHeuristic, com.linkedin.drelephant.spark.heuristics.ExecutorGcHeuristic] and following JobTypes [Spark].
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantContext : Supports MAPREDUCE application type, using com.linkedin.drelephant.mapreduce.fetchers.MapReduceFSFetcherHadoop2@27ab74e9 fetcher class with Heuristics [com.linkedin.drelephant.mapreduce.heuristics.MapperSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic, com.linkedin.drelephant.mapreduce.heuristics.MapperMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerSkewHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerGCHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ReducerMemoryHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic, com.linkedin.drelephant.mapreduce.heuristics.ExceptionHeuristic, com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic] and following JobTypes [Pig, Hive, OozieLauncher, Cascading, Voldemort, Kafka, HadoopJava].
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantRunner : executor num is 1
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantRunner : Fetching analytic job list...
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantRunner : Job queue size is 2
02-18-2019 12:23:37 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing MAPREDUCE application_1526555215992_0001
02-18-2019 12:23:37 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of MAPREDUCE application_1526555215992_0001 took 17ms
02-18-2019 12:23:37 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0003
02-18-2019 12:23:37 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0003 took 2ms
02-18-2019 12:23:37 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analyzing SPARK application_1526555215992_0002
02-18-2019 12:23:37 INFO  [dr-el-executor-thread-0] com.linkedin.drelephant.ElephantRunner : Analysis of SPARK application_1526555215992_0002 took 1ms
02-18-2019 12:23:37 INFO  [Thread-163] com.linkedin.drelephant.ElephantRunner : Main thread is terminated.
02-18-2019 12:23:37 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:23:37 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:23:37 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:false, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:23:37 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Cascading, for application type:mapreduce, isDefault:false, confName:cascading.app.frameworks, confValue:.*.
02-18-2019 12:23:37 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:HadoopJava, for application type:mapreduce, isDefault:true, confName:mapred.child.java.opts, confValue:.*.
02-18-2019 12:23:37 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded total 5 job types for 2 app types
02-18-2019 12:23:37 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:23:37 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:false, confName:pig.script, confValue:.*.
02-18-2019 12:23:37 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:23:37 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Spark, for application type:spark, isDefault:true, confName:spark.app.id, confValue:.*.
02-18-2019 12:23:37 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Pig, for application type:mapreduce, isDefault:true, confName:pig.script, confValue:.*.
02-18-2019 12:23:37 INFO  [pool-1-thread-1] com.linkedin.drelephant.configurations.jobtype.JobTypeConfiguration : Loaded jobType:Hive, for application type:mapreduce, isDefault:true, confName:hive.mapred.mode, confValue:.*.
02-18-2019 12:23:38 INFO  [play-akka.actor.default-dispatcher-4] org.hibernate.validator.internal.util.Version : HV000001: Hibernate Validator 5.0.1.Final
02-18-2019 12:23:41 WARN  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic : Mismatch in the number of files and their corresponding sizes for mapreduce.job.cache.archives
02-18-2019 12:23:41 WARN  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.DistributedCacheLimitHeuristic : Mismatch in the number of files and their corresponding sizes for mapreduce.job.cache.files
02-18-2019 12:23:41 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Could not find 4 threshold levels in 2, 4, 8
02-18-2019 12:23:41 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Could not evaluate 2& in 2&
02-18-2019 12:23:41 WARN  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuration foo2 is negative. Resetting it to 0
02-18-2019 12:23:41 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo4. Value is 0.5. Resetting it to default value: 50
02-18-2019 12:23:41 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo5. Value is 9999999999999999. Resetting it to default value: 50
02-18-2019 12:23:41 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo6. Value is bar. Resetting it to default value: 50
02-18-2019 12:23:41 WARN  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Configuration foo2 is negative. Resetting it to 0
02-18-2019 12:23:41 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo4. Value is 0.5. Resetting it to default value: 50
02-18-2019 12:23:41 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Invalid configuration foo6. Value is bar. Resetting it to default value: 50
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.Utils : Truncating foo-bar to 6 characters for id
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpillHeuristic : test_heuristic will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.ReducerTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : test_heuristic will use runtime_ratio_severity with the following threshold settings: [1.0, 2.0, 4.0, 8.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ShuffleSortHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [1.0, 5.0, 10.0, 30.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : test_heuristic will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.MapperSpeedHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericDataSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [10.0, 50.0, 100.0, 200.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use deviation_severity with the following threshold settings: [2.0, 4.0, 8.0, 16.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericSkewHeuristic : test_heuristic will use files_severity with the following threshold settings: [0.125, 0.25, 0.5, 1.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpeedHeuristic : test_heuristic will use disk_speed_severity with the following threshold settings: [0.5, 0.25, 0.125, 0.03125]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpeedHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 15.0, 30.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.ReducerTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use short_runtime_severity_in_min with the following threshold settings: [10.0, 4.0, 2.0, 1.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use long_runtime_severity_in_min with the following threshold settings: [15.0, 30.0, 60.0, 120.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperTimeHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 101.0, 500.0, 1000.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use gc_ratio_severity with the following threshold settings: [0.01, 0.02, 0.03, 0.04]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.GenericGCHeuristic : test_heuristic will use runtime_severity_in_min with the following threshold settings: [5.0, 10.0, 12.0, 15.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpillHeuristic : test_heuristic will use num_tasks_severity with the following threshold settings: [50.0, 100.0, 500.0, 1000.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.tez.heuristics.MapperSpillHeuristic : test_heuristic will use spill_severity with the following threshold settings: [2.01, 2.2, 2.5, 3.0]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use memory_ratio_severity with the following threshold settings: [0.6, 0.5, 0.4, 0.3]
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_default_mb with the following threshold setting: 2147483648
02-18-2019 12:23:41 INFO  [pool-1-thread-1] com.linkedin.drelephant.mapreduce.heuristics.GenericMemoryHeuristic : test_heuristic will use container_memory_severity with the following threshold settings: [1.1, 1.5, 2.0, 2.5]
02-18-2019 12:23:43 INFO  [Thread-374] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:43 INFO  [Thread-374] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:43 INFO  [Thread-374] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:43 ERROR [Thread-374] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:23:43 ERROR [Thread-374] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:23:43 INFO  [Thread-381] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:43 INFO  [Thread-381] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:43 INFO  [Thread-381] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:43 ERROR [Thread-381] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:23:43 ERROR [Thread-381] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:23:43 INFO  [Thread-388] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:43 INFO  [Thread-388] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:43 INFO  [Thread-388] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:43 ERROR [Thread-388] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:23:43 ERROR [Thread-388] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:23:43 INFO  [Thread-395] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:43 INFO  [Thread-395] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:43 INFO  [Thread-395] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:43 ERROR [Thread-395] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:23:43 ERROR [Thread-395] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:23:44 INFO  [Thread-402] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:44 INFO  [Thread-402] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:44 INFO  [Thread-402] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:44 ERROR [Thread-402] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:23:44 ERROR [Thread-402] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:23:44 INFO  [Thread-409] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:44 ERROR [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : Unable to retrieve the scheduler info for application [application_5678]. It does not contain [spark.driver.extraJavaOptions] property in its spark properties.
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.util.InfoExtractor : No Scheduler found for appid: application_5678
02-18-2019 12:23:44 INFO  [Thread-409] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:44 INFO  [Thread-409] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:44 ERROR [Thread-409] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:23:44 ERROR [Thread-409] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:23:44 INFO  [Thread-416] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:44 INFO  [Thread-416] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:44 INFO  [Thread-416] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:44 ERROR [Thread-416] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:23:44 ERROR [Thread-416] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:23:44 INFO  [Thread-423] com.linkedin.drelephant.ElephantRunner : Dr.elephant has started
02-18-2019 12:23:44 INFO  [Thread-423] com.linkedin.drelephant.analysis.HDFSContext : HDFS BLock size: 33554432
02-18-2019 12:23:44 INFO  [Thread-423] com.linkedin.drelephant.ElephantRunner : Backfill is not enabled
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: org.apache.oozie.client.$Impl_WorkflowJob@463e0cec
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0004166-160629080632562-oozie-oozi-W
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:23:44 ERROR [Thread-423] com.linkedin.drelephant.ElephantRunner : Unsupported Hadoop major version detected. It is not 2.x.
02-18-2019 12:23:44 ERROR [Thread-423] com.linkedin.drelephant.ElephantRunner : java.lang.RuntimeException: Unsupported Hadoop major version detected. It is not 2.x.
	at com.linkedin.drelephant.ElephantRunner.getAnalyticJobGenerator(ElephantRunner.java:134)
	at com.linkedin.drelephant.ElephantRunner.loadAnalyticJobGenerator(ElephantRunner.java:139)
	at com.linkedin.drelephant.ElephantRunner.access$100(ElephantRunner.java:59)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:158)
	at com.linkedin.drelephant.ElephantRunner$1.run(ElephantRunner.java:153)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:360)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1528)
	at com.linkedin.drelephant.security.HadoopSecurity.doAs(HadoopSecurity.java:109)
	at com.linkedin.drelephant.ElephantRunner.run(ElephantRunner.java:153)
	at com.linkedin.drelephant.DrElephant.run(DrElephant.java:67)
	at java.lang.Thread.run(Thread.java:748)

02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: workflowJob
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:23:44 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 12:23:44 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 12:23:44 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_url_template param for Oozie Scheduler
02-18-2019 12:23:44 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_exec_url_template param for Oozie Scheduler
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: scheduledChildJob
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0163255-160828184536493-oozie-oozie-C@1537
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action is scheduled with coordinator
02-18-2019 12:23:44 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 12:23:44 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
02-18-2019 12:23:44 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 12:23:44 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 12:23:44 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_url_template param for Oozie Scheduler
02-18-2019 12:23:44 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_job_exec_url_template param for Oozie Scheduler
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: scheduledChildJob
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0163255-160828184536493-oozie-oozie-C@1537
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action is scheduled with coordinator
02-18-2019 12:23:44 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_url_template param for Oozie Scheduler
02-18-2019 12:23:44 WARN  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Missing oozie_workflow_exec_url_template param for Oozie Scheduler
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Fetching Oozie workflow info for 0004167-160629080632562-oozie-oozi-W
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow for 0004167-160629080632562-oozie-oozi-W: manualChildJob
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie super parent for: 0004167-160629080632562-oozie-oozi-W: 0143705-160828184536493-oozie-oozi-W
02-18-2019 12:23:44 INFO  [pool-1-thread-1] com.linkedin.drelephant.schedulers.OozieScheduler : Oozie workflow 0004167-160629080632562-oozie-oozi-W@some-action was manually submitted
